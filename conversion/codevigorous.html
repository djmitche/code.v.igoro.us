<?xml version="1.0" encoding="UTF-8"?>
<!-- This Source Code Form is subject to the terms of the Mozilla Public
   - License, v. 2.0. If a copy of the MPL was not distributed with this
   - file, You can obtain one at http://mozilla.org/MPL/2.0/. -->
<!DOCTYPE html [
  <!ENTITY % htmlDTD
    PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "DTD/xhtml1-strict.dtd">
  %htmlDTD;
  <!ENTITY % globalDTD
    SYSTEM "chrome://global/locale/global.dtd">
  %globalDTD;
  <!ENTITY % feedDTD
    SYSTEM "chrome://browser/locale/feeds/subscribe.dtd">
  %feedDTD;
]>
<?xml-stylesheet href="codevigorous_files/global.css" type="text/css"?>
<html id="feedHandler" xmlns="http://www.w3.org/1999/xhtml">
  <head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <title>Code V.igoro.us (Login: Dustin J. Mitchell)</title>
    <link rel="stylesheet" href="codevigorous_files/subscribe.css" type="text/css" media="all" />
    <link rel="stylesheet" href="codevigorous_files/subscribe_002.css" type="text/css" media="all" />
    <script type="application/javascript" src="codevigorous_files/subscribe.js"></script>
  </head>
  <body onload="SubscribeHandler.writeContent();" onunload="SubscribeHandler.uninit();">
    <div id="feedHeaderContainer">
      <div id="feedHeader" dir="ltr" class="feedBackground">
        <div id="feedIntroText">
          <p id="feedSubscriptionInfo1"></p>
          <p id="feedSubscriptionInfo2"></p>
        </div>
        <div id="feedSubscribeLine"></div>
      </div>
    </div>

    <script type="application/javascript">
      SubscribeHandler.init();
    </script>

    <div id="feedBody">
      <div id="feedTitle">
        <a id="feedTitleLink" title="Go to RSS: Code V.igoro.us (Login: Dustin J. Mitchell) - Dustin J. Mitchell" href="http://code.v.igoro.us/">
          <img id="feedTitleImage" src="codevigorous_files/s9y_banner_small.png" />
        </a>
        <div id="feedTitleContainer">
          <h1 id="feedTitleText" xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" style="margin-right: 115px;">Code V.igoro.us (Login: Dustin J. Mitchell)</h1>
          <h2 id="feedSubtitleText" xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Dustin J. Mitchell</h2>
        </div>
      </div>
      <div id="feedContent"><div class="entry"><h3><a href="http://code.v.igoro.us/archives/1-USENIX-LISA.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">USENIX LISA</span></a><div class="lastUpdated">December 6, 2006 10:17 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So what better time to inagurate this blog than now, during the <a href="http://www.usenix.org/events/lisa06/tech/#keynote">keynote</a> to the <a href="http://www.usenix.org/events/lisa06/index.html">LISA (Large Installation Systems Administration)</a>
 conference.  It's an interesting general talk about one of the many 
pressing non-technical issues in this community: DRM and restrictive 
licensing.  </p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">He's 
boiled it down nicely: in the traditional crypto challenge, Alice 
talking to Bob, with Carol trying to eavesdrop, Carol has the ciphertext
 and the cipher, but not the key -- that's the feature that 
differentiates Carol from Bob, allowing Bob, but not Carol, to decrypt 
it.  But under DRM and other legal challenges Carol and Bob are the same
 person.  Companies are sending cyphertext to Carol/Bob, with the 
restriction that they can use it in one capacity (as Bob, the consumer) 
but not in another (as Carol, the same consumer who wants to watch the 
DVD on her computer).  Obviously, the only technical way to make this 
work is to control the cipher (the algorithm).  It's easy to build a 
cipher to do what they want.  It's technically impossible to prevent 
others from building ciphers that don't.  So they turn to the law.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
all reminds me of the "good old days" of the Apple II and crazy 
technical copy-protection schemes -- schemes which faded in popularity, 
and seem to have come back in the last decade.  Doctrow's answer was, to
 put it simply, DMCA. DMCA gave these companies the legal muscle they 
needed.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
keynote highlights what I'd like to talk about on this site -- I'm not 
much interested in posting code samples, or kvetching about this 
language or that language.  I'd rather talk about these much more 
important issues.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/2-Teaching-Problem-Solving-You-Can-and-You-Should-Elizabeth-Zwicky.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">"Teaching Problem Solving: You Can and You Should" (Elizabeth Zwicky)</span></a><div class="lastUpdated">December 6, 2006 11:06 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Mrs.
 Zwicky gave a really excellent talk that balanced real research in 
education, in problem solving, and in systems administration.  She 
teaches systems administration to Navy recruits for a defense 
contractor, in a tutoring setting.  The talk addressed the common belief
 that problem solving skills are essentially innate and can't be taught.
  She discussed the problem-solving process in general, using lots of 
examples (well, "war stories") from systems admin.  Finally, she talked 
about some of the techniques and skills needed to teach problem solving 
(or anything, really).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">These
 techniques included scaffolding -- building the learners' conceptual 
understanding by presenting the right tasks, offering the right support,
 and convincing the learner to talk about the concepts, not just "what 
do I type".  Also included was "spotting", which I assume comes from 
sports -- the idea here is to make sure that the learner doesn't suffer 
any horrible consequences from making mistakes. This topic was 
interesting to me, as someone who bridges education, systems 
administration, and development.  I think it's important for 
well-trained, intelligent people to think about and participate in 
education -- systems administrators included (for the record, I'm happy 
with the NSF's requirement that scientists do some sort of "community 
service" as a part of their work for a grant).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
found it relevant to me in two ways.  First, the person who replaced me 
at my previous job is a very green admin.  He's been doing basic IT 
legwork for a few years -- repairing computers, user support, etc.  Now 
he's in charge of a heterogenous Linux/Windows shop with a bunch of web 
services, funky applications, and so on.  Since he's in a production 
environment, questions are always "how do I do XYZ?" rather than "how 
does SSL work."  That makes it hard to concentrate on teaching the 
problem-solving that underlies all of this.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
have also tried to teach varoius IT-related things to a bunch of 
students (programming, administration, etc.).  For most, the motivation 
was missing, and I never figured out how to get around that.  For one, 
though, I found that spotting was an effective way to motivate her to 
actually try to solve a problem, rather than just requesting and 
following steps.  I asked her to add a printer to a Windows network, but
 said I wouldn't answer any questions, but would fix anything that broke
 while she was working on it.  It took a few iterations of the 
assurances before she started, and it took her a while to work through 
the process, but she now reflects on this as the best learning 
experience of our time working together.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">During
 the Q&amp;A session for this talk, I was somewhat disappointed that all
 of the questions focused on Problem Solving / System Administration -- 
horror stories, "what kind of problem solving is this", etc. -- nobody 
was interested in the teaching of these skills.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/3-Map-of-IPv4.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Map of IPv4</span></a><div class="lastUpdated">December 11, 2006 4:53 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><a href="http://xkcd.com/c195.html">This</a>
 is from a web comic, but it's a genius way to lay out the IP space.  I 
particularly like the way you can see the outlines of the old classful 
divisions, and get a good feel for what portion has been allocated.  I'm
 also amused that companies (like Google over on the left) are just 
specks. <a href="http://xkcd.com/c195.html"><img src="codevigorous_files/map_of_the_internet.jpg" /></a></p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/4-This-should-go-away%21.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This should go away!</span></a><div class="lastUpdated">January 6, 2007 11:25 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">One
 of the problems with coding in a high-level language is that sometimes 
the insulation from low-level details like memory management is not 
complete.  In this post, I present a method for debugging memory leaks 
in Python.
 </p><h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Garbage Collection</h2>
<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Python
 has two kinds of memory management: reference counting and a 
mark-and-sweep garbage collector for cycle elimination.  The reference 
counting takes care of immediately finalizing objects when the last 
reference to them goes away, such as when a variable goes out of scope, 
or a key is deleted from a mapping.  This takes care of the vast 
majority of objects, but the programmer has to be careful not to create 
cycles.  For example, consider this tree implementation:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">class Node:
    def __init__(self, parent=None):
        self.children = []
        self.parent = parent
        if parent: self.parent.children.append(self)

def make_tree():
    root = Node()
    kid1 = Node(root)
    kid2 = Node(root)
    return root
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Now <tt>root</tt>'s <tt>children</tt> references both <tt>kid1</tt> and <tt>kid2</tt>, but each of those nodes reference <tt>root</tt> via their <tt>parent</tt>
 attribute.  This forms a reference cycle (actually two), and simple 
reference counting will not finalize it.  For some time now, Python has 
had mark-and-sweep garbage collection to periodically seek and destroy 
these cycles.  Some time after the last reference to a cycle goes away, 
the garbage collection algorithm runs, identifies the cycle as garbage, 
and finalizes the objects in the cycle.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Leaks</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Even with full garbage collection, it's still easy to "leak" memory in Python:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>If large objects are involved in a cycle, they may "hold" their 
memory a lot longer than you'd like, leading to a 2-3x increase in 
memory consumption, depending on usage patterns.
</li><li>References can get "stuck" in unexpected places, such as <tt>sys.exc_info</tt>, <tt>threading.Thread</tt> instances, or function closures.
</li><li>If an object in a cycle has a finalizer (<tt>__del__</tt>), the garbage-collection algorithm cannot finalize it, and the entire cycle will persist.
</li></ul>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Leak-Hunting</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In the process of chasing what turned out to be several leaks in a large, long-running daemon, I developed a tool I'm calling <i>shouldGoAway</i>.  The idea is that the application being debugged calls <tt>shouldGoAway(obj)</tt> when it expects <tt>obj</tt> to go away soon.  The tool makes a weak reference to the object and waits one second.  If the object still exists, it uses the <tt>gc</tt> module to construct a reference graph for the object, and dumps that graph to disk in a format readable by <a href="http://www.graphviz.org/">GraphViz</a>.  Here's how it might be used:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">def compute():
    data_structure = get_data()
    process_data(data_structure)
    shouldGoAway(data_structure, "data_structure")
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The tool itself is <a href="http://code.v.igoro.us/files/shouldGoAway.py">shouldGoAway.py</a>.</p>

<h3 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Improvements</h3>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>This module creates a separate <tt>Timer</tt> for every call which 
can lead to a lot of resource consumption if lots of objects should be 
going away.  It would probably be sensible to switch to a single thread 
that processes objects sequentially.
</li><li>It would be nice to be able to adjust the delay before an object is checked.
</li><li>I think I've struck a nice balance of brevity and useful information in the graph, but there's room for improvement.
</li><li>Many objects (C types, tuples, lists, etc.) are not weak referencable.  It might be nice to work around this.
</li></ul></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/5-Old,-old-code.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Old, old code</span></a><div class="lastUpdated">January 6, 2007 3:40 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Once upon a time, I was a member of the <a href="http://www.syzygycult.com/">Syzygy Cult</a>, an active game-development group for the 680x0 macs.  Among the many games we wrote was <b>Mantra</b>,
 an adventure game with a top-down view similar to Legend of Zelda.  
Recently, the source code has re-surfaced (one of the other members 
found it in his parents' basement over the holidays). Judging by the 
dates in the source files, I was 16 at the time this was written, which 
means I had been programming for about 8 years.  At a general level, I'm
 blown away by the level of organization we had:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>Meeting minutes show we discusesd, agreed upon, and wrote down a 
policy for organizing header files: one per source file, with a single 
header that included all of them as well as common system includes.
</li><li>Several source files are annotated with e.g., "Reviewed DJM 6/23/94" -- we were doing <i>code review!</i>  
</li><li>The graphics routines were written in hand-tuned assembly.
</li><li>We used double-buffering to achieve smooth scrolling.
</li><li>We "hired" a graphic designer (as in, went out and found a guy 
we didn't know who would work for free) and gave him really explicit, 
detailed requests
</li></ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">My 
main contributions to the project were the graphics code (which also 
handled pixel-wise intercept detection) and the various in-game dialogs,
 like the items screen and the stores.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In
 a way, I feel like I've fallen off the trajectory I was on at that 
time.  If I was writing code like this at 16, after eight years of 
programming, where am I now, after twenty years?</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/6-Are-we-really-smarter.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Are we really smarter?</span></a><div class="lastUpdated">April 8, 2007 11:10 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I love reading old computer science texts.  I own the first three volumes of <u>The Art Of Computer Programming</u>,
 and while I can't claim to have read them all cover-to-cover, I often 
flip through them fairly randomly, and usually find some clever 
algorithmic trick or optimization that piques my interest.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Somehow I hadn't heard about <a href="http://www.inwap.com/pdp10/hbaker/hakmem/hakmem.html">HAKMEM</a> before.  It's an entirely <i>new</i> trove of puzzles to think about! </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/7-Improving-svnmerge.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Improving svnmerge</span></a><div class="lastUpdated">April 23, 2007 7:44 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">There's been a lot of writing about svnmerge: Ken Kinder <a href="http://kenkinder.com/svnmerge/">wrote a nice introductory article</a> on the topic, and now there's a <a href="http://www.orcaware.com/svn/wiki/Svnmerge.py">wiki</a> and even a <a href="http://www.orcaware.com/mailman/listinfo/svnmerge">mailing list</a>.  Maybe someday soon it will depart the <a href="http://svn.collab.net/repos/svn/trunk/contrib/client-side/svnmerge/">contrib/ purgatory</a>!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">One
 unusual use of svnmerge is to "branch" a public subversion repository 
into your local repository, to allow local development while still 
tracking the public trunk.  This is related to vendor branches, but is 
more suited to the case where you'll be submitting changes back to the 
project, and is particularly useful if you have commit permission on the
 public repository.  For me, I was merging from the Python repository (<tt>http://svn.python.org/projects/python/trunk/</tt>) to my own private repository (let's call it <tt> http://svn.v.igoro.us/python/trunk</tt>).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Svnmerge
 has a few weaknesses, but one that surprised me was this: while 
svnmerge can manage changes between different repositories, it <i>can't</i> do so when the repository-relative path is the same in each branch.  In this case, the repository-relative path for both is <tt>/python/trunk</tt>, so svnmerge complains:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">svnmerge: cannot init integration source '/python/trunk'
It must differ from the repository-relative path of the current directory.
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Getting Under The Hood</h1>
To understand why this limitation exists, you need to look at how 
svnmerge works its magic.  For each managed branch, svnmerge keeps a 
list of the revisions in the source branch that have been merged.  By 
default, this list is stored in the property <tt xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">svnmerge-integrated</tt>, looking like <tt xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">/python/trunk:1-54918,54920-54926</tt>.  When merging new changes (<tt xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">svnmerge merge</tt>),
 this property gets updated to reflect the newly merged revisions.  The 
problem, in this case, is that the identifier for the branch does not 
include any information for the repository: does this property list 
revisions in my repository, or in the Python repository?<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The Fix</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
solution I found to this problem was to qualify the properties with an 
identifier for the repository.  For most repositories, the obvious 
choice is to use a full URL, e.g., <tt>http://svn.python.org/projects/python/trunk:1-54918,54920-54926</tt>.  For repositories which might be accesed via different URLs by different people, the UUID might be a better idea, e.g., <tt>uuid://6015fed2-1504-0410-9fe1-9d1591cc4771/python/trunk:1-54918,54920-54926</tt>.
  To be general, I introduced the notion of a "location identifier" to 
specify the location of a branch.  Currently, there are three location 
identifier formats: </p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li><b>path</b>: the "old way" with a simple repository-relative path
</li><li><b>url</b>: a fully qualified URL for the branch
</li><li><b>uuid</b>: a UUID-based identifier
</li></ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">When initializing a new branch, you can specify one of these formats with the <tt>--location-type</tt> flag:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">$ svnmerge init --location-type uuid http://svn.python.org/projects/python/trunk
property 'svnmerge-integrated' set on '.'
$ svn pg svnmerge-integrated .
uuid://6015fed2-1504-0410-9fe1-9d1591cc4771/python/trunk:1-54928
</pre>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The Future</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Subversion
 1.5 promises to support merge tracking natively.  From what little I've
 seen, it does this using a similar technique -- keeping lists of 
revisions in properties.  However, the developers are not recommending 
that folks all convert to 1.5 immediately -- it looks like it will be a 
significant change that needs some serious testing first.  Even if it 
were stable, most Linux distros are so slow to upgrade that it's 
reasonable to assume we'll all be using 1.3 for a good while.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This patch is in the submission process on the mailing list, but an updated version of svnmerge.py is available <a href="http://code.v.igoro.us/files/svnmerge.py">on this site</a>, if you'd like to take it for a spin.  Any feedback would be appreciated!</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/8-Programming-Challenge-Sudoku-Generator.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Programming Challenge: Sudoku Generator</span></a><div class="lastUpdated">April 24, 2007 12:02 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Write a program to generate sudoku puzzles with a unique solution.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In Postscript.  </p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In such a way that if I print 5 copies of your program, I get five distinct sudoku puzzles.
 </p><h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Clarifications</h2><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>The puzzles should, at most, specify 25 of the 81 spaces.
</li><li>Programs that simply take an existing puzzle and apply transformations will be frowned upon mightly.
</li><li>If it crashes my printer, it doesn't qualify.
</li></ul></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/9-Open-Source-Support.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Open-Source Support?</span></a><div class="lastUpdated">June 16, 2007 3:01 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I saw an <a href="http://svn.haxx.se/tsvn/archive-2007-06/0114.shtml">interesting post on the Subversion development list</a> a while ago.  In part:</p>

<blockquote xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
This note is to inform you that the Shell Group will be migrating from 
Windows 2000 to Microsoft's new operating system known as Windows Vista 
with effect from Q1 2008, and to seek your assistance and support in 
minimising disruption to users and applications during and after the 
migration.
</blockquote>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
note goes on to request some fairly specific information about the 
upgrade path for TortiseSVN, the Windows Subversion client.  They are 
the sorts of questions that all IT shops would love to ask all of their 
vendors, with the expectation of a full and well-researched answer.  </p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">As
 an admin at a small K-12 school, questions of this sort were met with 
blank stares from vendors.  At best, we could get a demo unit, but any 
sort of analysis of the potential fit of a product (besides the 
"analysis" the salesmen would do) was simply out of the question for an 
account of our size.  On the other hand, I could usually count on honest
 assessments from open-source software mailing lists, even if they 
didn't represent full-scale implementation analyses.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The
 Shell Group request turns the situation around.  Shell Group is a very 
large client and is probably accustomed to contacting peers like Dell, 
Aramark, or HBN-AMRO with requests like this.  Yet here they are making 
these requests of a gaggle of developers, <i>none</i> of whom want to be
 "the main liaison for ALL matters pertaining to Vista compatibility."  
There were no on-list responses, so I can't say what became of the 
request.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">There's
 clearly a business need here, but it's not the typical "sell support 
for open source software" niche.  Rather, Shell Group wants a business 
entity with which they can have a more contractual relationship: one 
that can get the software certified by Microsoft, make projections as to
 deliverable dates, and so on.  An entity that can answer support calls 
but does not have significant control of the development community is 
simply not capable of these things, but neither is a development 
community without a legally representative organization.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I'm
 interested to see if this kind of request occurs more often, and what 
effect it has on the landscape of adoption of OSS in big business. </p><h3 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Fact-Checking</h3>
Some basic googling for other messages like this turned up nothing.  
It's quite possible that this is a hoax.  If so, I'm sorry for promoting
 it, but I think the points it brought up are interesting nonetheless.<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/10-Chicago-Coffeeshops.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Chicago Coffeeshops</span></a><div class="lastUpdated">September 5, 2007 12:04 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Since I telecommute, I spend a lot of time in the house.  Sometimes I just need a change of scenery.  Here are the places I go:
</p><center xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<br /><small><a href="http://maps.google.com/maps/ms?ie=UTF8&amp;hl=en&amp;msa=0&amp;msid=113563694508286633526.00000111c2bd77999eb9b&amp;om=1&amp;ll=41.934211,-87.647196&amp;spn=0.284934,0.11842&amp;source=embed">View Larger Map</a></small></center> <p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/11-Open-source-contributors.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Open-source contributors</span></a><div class="lastUpdated">September 6, 2007 12:58 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">There
 have been a few interesting sites popping up lately to do some 
large-scale analysis of open source applications and the developers 
behind them.  <a href="http://www.ohloh.net/">ohloh</a> is one such 
site.  Ohloh analyzes the source to extract license and language 
information, and also looks at the relative contributions of various 
authors, based on commits.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The <a href="http://www.ohloh.net/projects/5128?p=Amanda">Amanda report</a> shows some warnings:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>Small development team
</li><li>Short source control history
</li></ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The first is something I'd like to change -- if you're looking for an open source project, have I got a deal for you!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
second is actually an artifact of the switch to Subversion -- a much 
longer history is available in SourceForge's CVS repository, but when 
the project switch to subversion, it was imported in a single revision, 
rather than using cvs2svn.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">EDIT: fix typo in the title </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/12-Perl-vs.-Python.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Perl vs. Python</span></a><div class="lastUpdated">October 19, 2007 4:05 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Oops.  I inadvertently started a small skirmish in the ongoing language wars.  It began when I <a href="http://code.v.igoro.us/%3Ca%20href=">suggested</a> rewriting the bulk of <a href="http://www.amanda.org/">Amanda</a> in a scripting language.
</p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
The denizens of this list are mostly seasoned UNIX admins and open 
source programmers with an sysadmin background.  To my understanding, 
this is also the "core constituency" of Perl's popularity -- it's a 
language that lets admins Get Stuff Done.  Parts of Amanda are already 
written in Perl, so I thought Perl was a shoo-in for Amanda's new 
scripting language.
</p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
Well, the discussion isn't over yet, but I was very surprised to see that Python, my <a href="http://www.urbandictionary.com/define.php?term=bffl">BFFL</a>
 among scripting languages, was strongly suggested by a number of 
participants, while only one person offered a solid vote for Perl.
</p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
I wonder: have I been out of touch, or are tides starting to shift?  
It's interesting that allegiances would shift for languages which have 
been around for so long (Python <a href="http://en.wikipedia.org/wiki/Python_%28programming_language%29">was first released in 1991</a>, Perl-1.0 <a href="http://perldoc.perl.org/perlhist.html">arrived in 1987</a>). </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/13-Programming-Contests-and-Puzzles.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Programming Contests and Puzzles</span></a><div class="lastUpdated">December 24, 2007 11:59 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
In August 1992, inCider/A+ magazine ran a programming contest, the rules
 for which were "[U]se the IIGS assembly language source code supplied 
by the FTA to complete their Bouncin' Ferno game."  The game was a 
marble-madness clone, written entirely in assembly by a bunch of French 
hackers.  The code played some fairly devious tricks, as assembly often 
does, and was sparsely commented -- and in French, at that.  Anyway, I 
spent something like a year rewriting the game from scratch, again in 
assembly, and adding a number of new features.  A year later, I won the 
contest (admittedly, probably as the only entrant) and rode a wave of 
fame and fortune through a few random apple user's groups in central 
Maine.
</p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
Since then, I've had a fascination with programming contests and related puzzles, even leading me to post a challenge <a href="http://code.v.igoro.us/archives/8-Programming-Challenge-Sudoku-Generator.html">here in April</a> (which I still haven't solved).<br />
</p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
Even though I'm not interested in a new job, I was excited to hear about what came to be known as <a href="http://wanted-master-software-developers.com/?key=">the N-BRAIN problem</a>.
  The first problem, an exercise in test-driven development, was 
interesting, although a bit frustrating due to the rather limiting 
development environment.  The remaining parts of the problem, however, 
were just ridiculously obfuscated, rather than being clever.  I suppose 
that means the job wasn't for me, anyway.
</p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
I am even more interested to see <a href="http://projecteuler.net/">Project Euler</a>,
 a collection of interesting mathematical and algorithmic problems 
ranked by difficulty.  The site may very well wind up on my list of 
places to waste time while waiting for compiles (along with Google 
Reader and <a href="http://play.intrade.com/">intrade</a>).
</p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
Ah, how I miss the halcyon days of high school, when everyone I knew 
spent as much time as I did immersed in code, and when a spat over the 
best algorithm for 3d collision detection could leave friends not 
speaking for days.  I hate to say it, but I think I was a better hacker 
then than I am now.  Perhaps I can interest someone in a head-to-head 
challenge? </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/14-Safaris-Web-Inspector.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Safari's Web Inspector</span></a><div class="lastUpdated">January 12, 2008 11:55 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I
 try not to do web development anymore, but it's hard to avoid.  I just 
encountered some CSS weirdness with (brace yourself) IE7, and wanted to 
look at what the CSS actually said, so I clicked "Show Web Inspector" on
 Safari's "Debug" menu.  I was completely blown away by <a href="http://weblogs.asp.net/davidbarkol/archive/2007/06/22/web-inspector-for-safari-on-windows.aspx">the result</a>.
  The tool has a very intuitive DOM viewer, which shows everything you 
could want to know about a node, and also hilights the result 
beautifully in the original page.  The "Network" icon shows a great view
 of the load time for the page, helping to diagnose all of those slow 
loads.  And the "Console" icon gives warnings from the XML/HTML parser! 
 All those little typos that go unnoticed on all but one version of one 
obscure browser?  Safari will actually tell you about them!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This is how you build a developer tool.  Wow. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/15-Retroactive-Unit-Tests.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Retroactive Unit Tests</span></a><div class="lastUpdated">February 7, 2008 7:16 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Amanda
 has, for a long time, shipped with an asynchronous communication 
library, called event.  It supports the usual suspects: reading and 
writing file descriptors, timeouts, and arbitrarily triggerable events. 
 It's actually commented a bit better than most of Amanda, but only with
 vaguely suggestive sentences, rather than rigorous descriptions of 
behavior.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">It has come time to "re-base" this particular library to use glib's <a href="http://library.gnome.org/devel/glib/unstable/glib-The-Main-Event-Loop.html">GMainLoop</a>,
 because other, newer parts of the code will be based on GMainLoop, and 
everyone needs to play nice together.  The process is relatively clear: 
write thorough unit tests against which the existing implementation 
passes, then check the new implementation against those tests.  This 
means writing unit tests against existing code that someone else wrote. 
 That's hard.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">My 
initial selection of unit tests gave my new implementation a PASS on the
 first try, so I fired up a backup process, which seemed to work, and 
then a recovery, which failed miserably.  Many, many hours of 
hand-tracing code later, I uncovered two behaviors of the event library 
which were completely undocumented.  I won't make a guess as to whether 
they were <i>intentional and undocumented</i> or <i>unintentional and just happened to work</i>.  I've now adjusted the comments appropriately, and added unit tests to tickle the funny behavior, but things are still broken.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">[EDIT: this sat in my "drafts" folder for no reason] </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/16-Girls-and-Math.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Girls and Math</span></a><div class="lastUpdated">February 18, 2008 9:46 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><img alt="" src="codevigorous_files/how_it_works.png" /><br clear="all" /></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Every girl gets the memo:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">To: Girls
From: The Establishment
Re: Math

Math is hard, and you'll never need it anyway.  
You'll just be cooking and making babies, after all.

cc: Boys
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">But 
most teen girls, being the modern anti-establishment type, reject this 
sentiment as "the man" trying to keep them down.  They look to the 
female role models around them for guidance as to what "real life" is 
like.  That comes down to teachers, moms, aunties, and big sisters.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Last 
week, while I was working on an algebra problem with a group of 
7th-grade girls, the classroom teacher (a woman) said, "I'm not good at 
math."</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">To: Girls
From: Grown-up Girl
Re: Math

I never learned math, and now I'm a teacher, so you can safely ignore it.
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">But what did this teacher really mean?  She can solve the problem we were working on, no problem.  What's hard is <i>teaching</i>
 math.  As with most subjects, a teacher needs to be agile enough to 
dance around the math, attacking it from all angles, spotting the 
misconceptions and shreds of understanding in a student's responses, and
 asking the right questions.  </p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">That's
 legitimately hard, and I think it's unreasonable to ask someone to be 
this good at more than one subject.  I'm a pretty OK math teacher, but 
if you plop me down in front of a language arts class, I'll struggle.  
I'm OK with that, but the proper phrase is "I'm not good at teaching 
language arts," not "I can't read."</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/17-Ohloh.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Ohloh</span></a><div class="lastUpdated">April 22, 2008 11:30 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Some
 time back, I had been thinking of trying to trace the "social network" 
of open source developers.  I'm interested questions like</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>How many open-source developers contribute significantly to multiple projects? How many projects?
</li><li>Is the set of developers reasonably well-connected by the "works on a project with" relation?
</li><li>What proportion of projects are basically single-developer projects?
</li><li>What is the distribution of number of developers per project, 
and relative levels of contribution from those developers?  How unique 
is the Linux kernel in having a large set of substantial contributors?
</li><li>How many open-source projects are there (above some level of completeness and activity)?
</li></ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Long 
story short, I had grand plans for parsing VC histories, ChangeLogs, 
AUTHORS files, and so on, but never got around to actually coding 
anything.  Then I found <a href="http://ohloh.net/">Ohloh</a>.  They've 
taken the liberty of indexing a lot of publicly available code, and have
 some web-based knobs that you can tweak to clean up some of their data.
  They have REST API available to access their data, and some of their 
code (their SLOC counter) is open source.  I'm pretty impressed.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
will probably try out the API and see if I can answer some of these 
questions, but I worry that their database is quite dirty.  They rely on
 individual users to log in to the site and "claim" their identity -- 
connecting e.g., their SourceForge login to their Berlios.de login to 
their logins on project-specific sites.  I would like to see them apply 
some additional intelligence to matching users up; for example, email 
addresses appear in lots of locations (ChangeLogs, AUTHORS, commit 
messages), and provide a fairly reliable proxy for a particular person.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/18-Building-an-Organic-open-source-community.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Building an "Organic" open-source community</span></a><div class="lastUpdated">May 11, 2008 10:45 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I just stumbled on Ted T'so's <a href="http://thunk.org/tytso/blog/2008/04/26/organic-vs-non-organic-open-source-revisited/">Organic vs. Non-Organic Open Source, Revisited</a>.
  The distinction is that an organic open source community has a diverse
 development community, in terms of motivations or, more concretely, 
employers.  Conversely, a non-organic community is dominated by 
developers from a single company.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
has put words to a question I've been wrestling with for a long time.  
In any community, those who do the most work have the strongest voices 
and the most power.  As someone who knows his way around the Amanda 
codebase, I hold the fate of a user's feature request in my hands: if I 
like it, I can implement it, and if I don't, it will be relegated to the
 dusty archives of the amanda-users list.  Similarly, when I make a 
proposal, non-developers must respond in a subordinate voice: "well, I 
won't be writing it, but I think .."  This is not due to any malice on 
my part, but simply a fact of the relationship of consumer to producer.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
bulk of Amanda development is currently performed by Zmanda employees.  
That's a simple fact that Ohloh can verify for you.  That makes the 
Amanda development community non-organic, in Ted's terminology.  In 
Raymond's terms, we're all cathedral and no bazaar.  As Ted points out, 
this can be a good thing -- I think that we do great work, and that we 
go out of our way to listen and respond to the user community's ideas 
and requests.  A tight group of developers can move quickly, and 
consensus decisions are easier and less time-consuming.  However, power 
corrupts, and I would <i>like</i> to have other developers out there to tell me, "no," or, "I have a better way," occasionally.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">But how?</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/19-More-girls-+-math.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">More girls + math</span></a><div class="lastUpdated">May 31, 2008 1:26 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I'm
 watching the DNC's Rules &amp; Bylaws Committee meeting, discussing the
 fate of the Michigan and Florida delegations.  This committee consists 
of the elite among the Democratic superdelegates.  These are all 
powerful, intelligent, important people (including the wonderful Donna 
Brazile).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What
 has me upset is that I've now heard two women explain that they don't 
have the "mathematical genius" to work out the proper representation for
 these states; no men have made such a declaration.  First of all, 
that's bull: anyone can work out what 33% of 128 is.  The difficult part
 is in the politics, and everyone on this committee is an expert on 
politics.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">More
 importantly, though: why is it OK for these women to brag about their 
mathematical ignorance?  What message does this send to PoliSci students
 struggling through calculus?  One of the women to mention this was 
Alice Travis Germond, who was a VP of NARAL -- hardly an advocate of 
keeping women barefoot, pregnant, and in the kitchen.  What is she 
thinking?</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">[UPDATE] The other woman to brag about her innumeracy was Tina Flournoy -- Gore's finance director!  Finance! </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/20-roll-back-a-git-svn-mirror.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">roll back a git-svn mirror</span></a><div class="lastUpdated">December 2, 2008 11:15 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Several <a href="http://amanda.org/">Amanda</a>
 developers use git internally, but the Amanda source code is in 
Subversion at SourceForge.  Git-svn manages bidirectional mirroring for 
us, and works flawlessly.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Recently,
 however, we introduced a problem through user error: due to a typo in 
our git-authors file, a bunch of revisions were mirrored with incorrect 
author information.  This was more than a cosmetic problem because it 
caused the SHA1 hashes to differ between developers who fixed the typo 
at different times (because the author information is included in the 
data that feeds the hash algorithm).  This would leave us with divergent
 commits forever.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
challenge, then, is to make git-svn think that it never fetched that 
revision.  HEAD was at r1413, but r1391 had the bad author.  We branched
 for release right after the bum commit, so there are two branches to 
deal with.  Here's what I did:</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">First, roll back the remote branches (e945b67d78c239b42cb882e5c28e24354d0c05f0 is r1390)</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">$ git update-ref -m "roll back git-svn" ext/trunk e945b67d78c239b42cb882e5c28e24354d0c05f0
$ git update-ref -m "roll back git-svn" -d ext/amanda-261 cad126843a7649ca3e05088dd46ee41d7f17e7e2
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Next, edit both maxRev values in git-svn's metadata (<tt>.git/svn/.metadata</tt>):</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">[svn-remote "ext"]
    reposRoot = https://amanda.svn.sourceforge.net/svnroot/amanda
    uuid = a8d146d6-cc15-0410-8900-af154a0219e0
    branches-maxRev = 1413
    tags-maxRev = 1413
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Finally, delete the .<em>ref</em>log</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">$ rm .git/svn/ext/trunk/.rev_map*
$ rm .git/svn/ext/amanda-261/.rev_map*
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Then just re-run the fetch:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">$ git svn fetch ext
</pre></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/22-git-prompt-addition.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">git prompt addition</span></a><div class="lastUpdated">February 1, 2009 1:25 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Now
 that I'm using git all the time, it's helpful to have bash show me what
 branch I'm on, and whether the working directory is dirty.  I found a <a href="http://henrik.nyh.se/2008/12/git-dirty-prompt">gist by Henrik Nyh</a>
 that does just this.  I souped it up a little bit to be more efficient 
and handle a few extra situations.  Here's the result:
[EDIT: I have updated this gist since this post was made; the current 
version is based on git-completion.sh in the git distribution]</p>



<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Please use it if you like, and fork the gist if you make any improvements! </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/23-Class-in-open-source-projects.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Class in open-source projects</span></a><div class="lastUpdated">August 3, 2009 7:05 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">(from a comment on <a href="http://www.zenofnptech.org/2009/08/diversity-and-open-source.html">Zen and the Art of Nonprofit Technology</a>)</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I've 
realized recently that open-source projects have developed a class 
structure.  First, consider the broad middle-class of little-known but 
functional projects that have a number of users and several developers 
(Amanda, Buildbot, Cfengine, Sphinx, Curl, the autoconf archive, maybe 
GMT).  Above these projects are the superprojects that nearly everyone 
uses and that have hundreds of contributors (Firefox, Linux, Python, 
Perl, to name a few).  These are all islands in a squalid sea of 
abandonware and single-developer projects -- we've all got one or two, 
right?</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What 
are the keys to mobility between these classes?  What factors might keep
 an otherwise-deserving project in the lower or middle classes?</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/24-Users-and-their-Motivations.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Users and their Motivations</span></a><div class="lastUpdated">August 12, 2009 10:44 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I stumbled upon a summary of the Drefyus model of skill acquisition by Andrew Hunt today, copied out of the powerpoint <a href="http://www.codinghorror.com/blog/archives/000203.html">here</a>.  There's a bullet point in there that I hadn't seen before:</p>

<ol xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>Level 1: Beginner
<ul>
<li> Little or no previous experience
</li><li> <b>Doesn't want to learn: wants to accomplish a goal</b>
</li><li> No discretionary judgement
</li><li> Rigid adherence to rules
</li></ul>
</li></ol>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I've been toying with the idea of a beginner's guide to <a href="http://amanda.org/">Amanda</a>
 for some time.  My vision was of a shallow but broad description of how
 Amanda fits together: clients and servers, applications, holding disks,
 changers, devices, and so on.  Scaffolding, in the constructivist 
sense.  The intent was to head off some of the more ignorant questions 
about Amanda, and give beginners a base on which to build their own 
Amanda configurations.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">But 
this won't work!  A beginner does not want to learn, and anything that 
tries to "teach" a beginner is just so much noise to him or her.  In 
fact, most beginner guides are nothing of the sort -- they are probably 
only useful to those already at level 2.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This
 is all the more the case with Amanda: like plumbing, Amanda users just 
want backups to happen so they can concentrate on their core business, 
so even smart folks will happily remain at level 1 if they can make it 
work.  So what can we do to support these users?  And how can we 
encourage people to move to the next level?</p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"> </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/27-GCC-warnings.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">GCC warnings</span></a><div class="lastUpdated">December 21, 2009 11:18 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I
 love the fact that GCC has basically eliminated the need to run lint, 
by adding every imaginable warning.  But there are two problems.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">First, generated code (at this point I'm being bitten by code generated by rpcgen for <a title="ndmp-src/" href="http://github.com/zmanda/amanda/tree/master/ndmp-src">NDMJOB</a>)
 seldom runs without warnings.  Usually these are the "unused XXX" 
warnings, but some generated code is really and truly broken - K&amp;R 
style definitions, signed/unsigned confusions, the works.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Second, warnings come and go between GCC versions, so just because it runs fine on <em>my</em>
 system does not mean it will run fine on all of the GCC's Amanda gets 
built on (never mind any other compilers!).  Here's where I find myself 
trying to figure out how to disable a particular bogus warning for some 
ancient version of gcc, which is naturally not in the manuals now 
available on the web.  And here's where my favorite GCC trick is handy: <tt>-fdiagnostics-show-option</tt> will cause gcc to display the <tt>-W</tt>
 option that controls that particular warning.  From there, you can 
google the warning, or just disable it if you've determined that it's 
spurious and not worth the code changes required to make it go away.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I thought I'd throw that up here so I don't forget about it again.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/28-Underhanded-C-Contest.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Underhanded C Contest</span></a><div class="lastUpdated">December 30, 2009 6:42 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><a href="http://underhanded.xcott.com/?p=18">This contest</a>
 recently came to my attention.  I think I'll give it a shot.  The 
challenge isn't too clear -- exactly what constitutes a "superseded" 
order is left pretty vague -- but there are lots of opportunities for 
underhandedness in the task. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/29-Modern-Multiprocessing.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Modern Multiprocessing</span></a><div class="lastUpdated">April 12, 2010 4:24 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I've
 been thinking a lot lately about the way we accomplish multiprocessing.
  We've seen a significant change in the operation of Moore's law for 
CPU speeds: today's CPUs are about the same speed as those of a few 
years ago, but they have more cores, and more virtual processors on 
those cores.  This is great for heavily-loaded servers, which have 
plenty of distinct tasks to place on those cores and VCPUs, but not so 
useful for users working with single-threaded applications.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Why 
are most applications still single-threaded?  There are lots of good 
reasons. Threaded code is harder to write, and not just because it 
requires careful analysis and use of synchronization primitives: many 
common tasks are difficult to meaningfully parallelize without careful 
control over inter-thread communication, and in a portable application 
you don't have that kind of control.  Threaded code generally performs 
badly on single-CPU systems, which are still common.  Some popular 
languages still make threading difficult, at least in a portable 
fashion.  And threads are still relatively heavyweight entities in most 
operating systems: you don't spawn ten threads to mergesort a 100-item 
array.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Some of these problems will go away with a little more time, but some will get worse.  <a href="http://en.wikipedia.org/wiki/Non-Uniform_Memory_Access">NUMA</a>
 architectures can make sharing data between threads slow.  
Hyperthreading and its interaction with processor caches adds yet 
another level of unpredictability.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">We 
know how to build massively parallel systems that run massively parallel
 algorithms.  What is still unknown is how to build portable, simple 
software that can run efficiently across a vareity of architectures.  
This is a problem of practice, not theory, and there's lots of 
interesting work going on in this area.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Of course, there are languages designed explicitly to support communication, such as <a href="http://www.vitanuova.com/inferno/papers/limbo.html">Limbo</a> or <a href="http://www.erlang.org/index.html">Erlang</a>, <a href="http://www.haskell.org/">Haskell</a>, and <a href="http://clojure.org/">Clojure</a>.
  For the most part, these languages are structured as communicating 
sequential processes, which is to say that they represent 
multiprocessing as a set of sequential threads that pass information to 
one another.  Problems of thread safety are subsumed by the languages, 
but mapping the parallelism to available resources is generally left to 
the programmer or administrator.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">One interesting project is Apple's <a href="http://developer.apple.com/mac/articles/cocoa/introblocksgcd.html">Grand Central Dispatch</a>.
  It defines a simple but highly expressive closure syntax (a block) and
 a mechanism to dynamically schedule execution of such closures 
(queues).  Critically, the GCD library takes care of scaling the 
parallelism of the queue processing appropriately to the underlying 
hardware.  On a single-threaded CPU, this amounts to cooperative 
multitasking, but on parallel hardware the operating system can 
dynamically allocate virtual CPUs to applications needing more 
parallelism.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This topic seems to come up often in my various pursuits, so I will return to it again. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/30-Object-identity-in-Perl.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Object identity in Perl</span></a><div class="lastUpdated">January 22, 2010 12:02 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I ran across a surprising weakness in Perl, regarding object identity.  I was writing a function to handle <a>XMsgs</a>,
 which are messages used by the Amanda transfer architecture to indicate
 the progress of a transfer.  Messages sent from any transfer element 
are delivered to the same handler, and in this case I needed to know 
which element had sent the message.  Fortunately, XMsg objects have a <tt>elt</tt> attribute pointing to the sending element.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Now, in Python, I would write,</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">  def handle_xmsg(xmsg):
    if xmsg.elt is interesting_elt:
      # handle message from interesting_elt
    else:
      # handle message from other elements
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">where the <tt>is</tt> operator tests for object identity.  So how do I do this in perl?  My first thought was to use <tt>eq</tt>, since the string interpolation of a hashref seems to have an object identifier in it: <tt>HASH(0x711210)</tt>.  I soon learned, in #perl, that <tt>==</tt>
 would work better, as the hashref's address is used as its integer 
value, and this conversion is much faster than stringification.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">However, the element objects in this particular case are SWIG objects, and furthermore they use <tt>overload</tt> to implement a user-readable stringification.  So neither technique worked.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What I did end up doing was this:</p>



<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I overrode the <tt>==</tt> operator, and wrote a short comparison function in C to compare the un-SWIGged, un-magicked, un-blessed object pointers.  Whew!</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/31-A-future-for-Svnmerge.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">A future for Svnmerge?</span></a><div class="lastUpdated">January 17, 2010 3:34 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Svnmerge has always been the kid brother of Subversion.  It's in the project's <a href="http://svn.apache.org/viewvc/subversion/trunk/contrib/client-side/svnmerge/">contrib</a>
 directory, and is thus unversioned.  Since it's a single Python script,
 users just download it directly from the repository.  In the last year,
 the script has only seen a few non-trivial commits, and the <a href="http://www.orcaware.com/mailman/listinfo/svnmerge">mailing list</a> has been almost silent.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">There
 are some simple reasons for decline.  First, Subversion itself, in 
version 1.5, has adopted some of the functionality of Svnmerge.  In 
particular, svn now uses properties (<tt>svn:mergeinfo</tt>) to track 
the revisions that have and have not been merged into a particular 
branch.  There are some limitations, of course.  Most obviously, a 
branch can only be "reintegrated" into trunk once, which is not the 
workflow of many Svnmerge users.  Also, to my knowledge, Subversion 
cannot merge between repositories, while Svnmerge can.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Second,
 Git, Mercurial, and other DVCS's now provide strong support for 
merge-heavy workflows.  Both tools also have excellent "gateways" to 
Subversion.  For example, Amanda's <a href="http://github.com/zmanda/amanda/">Github repository</a> tracks the <a href="http://amanda.svn.sourceforge.net/viewvc/amanda/">Subversion repository</a> using some simple shell scripts.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Between
 these two forces, I think that much of the audience for Svnmerge has 
disappeared.  Those left, sadly, will see even less support. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/32-2005-Mac-Mini-as-an-Arduino-Development-System.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">2005 Mac Mini as an Arduino Development System</span></a><div class="lastUpdated">January 23, 2010 7:00 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I
 have an early Mac Mini that's not good for much of anything anymore.  
It's not too fast, and it's a 32-bit PPC chip, so most proprietary-blob 
software is off-limits, meaning it doesn't make a good media PC.  I put 
Gentoo on it, and decided to use it to interface with my new Arduino 
Duemilanove.  I'm more interested in the Arduino as a processor I can 
play with, rather than a gateway to flashing LEDs, so I don't want the 
full IDE - just a compiler and assembler, and a USB-based programmer.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This post documents the process I followed to set all of this up. </p><h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Smoketest</h2>
As a smoketest, I downloaded the Arduino application on my Macbook and 
modified one of the blinkie examples to make a chaser for a 7-segment 
display I had handy.  I tweaked the code, hooked up some jumpers, and 
clicked the "Upload" button.  The code was pretty simple, but I did 
encounter an elementary digital logic problem: my display was 
common-anode, but a digital HIGH is +5V.  I can't simply ground the 
common pin - what to do, then?  My confusion was based on the false 
assumption that logic LOW is unconnected - of course, it's actually 
ground.  So I connected the common anode to the +5V rail, and set up to 
illuminate each segment with a LOW digital out signal (routed through a 
220 resistor).  Here's the code:<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>



<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Software</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Next up, installing the requisite software on the Mini.  First, the crossdev tools.  Most documentation suggests simply:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">emerge crossdev
crossdev --target avr
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">But this failed:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"> * ERROR: cross-avr/avr-libc-1.6.4 failed.
 * Call stack:
 *               ebuild.sh, line   49:  Called pkg_setup
 *   avr-libc-1.6.4.ebuild, line   40:  Called die
 * The specific snippet of code:
 *              die "AVR toolchain not found"
 *  The die message:
 *   AVR toolchain not found
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The solution, available from <a href="http://bugs.gentoo.org/230343">Gentoo bug #230343</a>, is to add the <tt>--without-headers</tt> flag, which instructs the crossdev tool to build the compiler first, then the C library.  The <tt>-s4</tt> builds a stage-4 compiler, including the C++ frontend.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">crossdev -s4 --target avr --without-headers
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This takes a <i>long</i> time on a system of this vintage.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">While I was in the root shell, I installed <a href="http://avra.sourceforge.net/">avra</a>, an AVR assembler:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">emerge avra
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Next 
up, the kernel driver.  For the particular board I have, I need kernel 
support for the FTDI USB-to-serial chip.  The driver is <tt>ftdi_sio</tt>, and the kernel option is <i>Device Drivers -&gt; USB Support -&gt; USB Serial Converter Support -&gt; USB FTDI Single Port Serial Driver</i>.  If you happen to be on a PPC machine, don't forget to run <tt>ybin -v</tt> after upgrading the kernel.  With this set up, the USB serial device appears at <tt>/dev/ttyUSB0</tt>.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Finally, the programmer.  I'm using <a href="http://www.nongnu.org/avrdude/">avrdude</a>.
  I installed this from portage.  I had to install version 5.8 
(keyworded ~ppc) to get the ATMEGA328P support.  The problem is, avrdude
 doesn't automatically reset the device by pulsing DTR. The Arduino IDE 
does this just before running avrdude.  There is a patch available on <a href="http://savannah.nongnu.org/patch/?6866">Avrdude bug #6866</a>,
 but it hasn't yet been merged.  Rather than try to set up an avrdude 
ebuild in a local portage overlay, I opted for the simpler solution 
described <a href="http://www.arduino.cc/cgi-bin/yabb2/YaBB.pl?num=1201441300">in the arduino.cc forums</a>: reset the device with a perl script just before invoking avrdude.  The code is simple:</p>



<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I needed to emerge dev-perl/Device-SerialPort first. Then, to upload a new program:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">./pulse &amp;&amp; avrdude -c arduino -b 57600 -p m328p -D -U flash:w:/tmp/Blink.cpp.hex:i -P /dev/ttyUSB0
</pre>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Compiling</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Up to
 now, I've been using Blink.cpp.hex, compiled earlier on the Macbook.  
Now it's time to start building locally.  All of the libraries and 
headers that make an Arduino sketch into an executable are in the <tt>dev-embedded/arduino</tt> ebuild.  I keyworded this (~x86 since there's no ppc keyword in the ebuild) and added <tt>USE=-java</tt> since I don't need the IDE, and emerged it.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I copied <tt>/usr/share/arduino-0017/hardware/cores/arduino/Makefile</tt> into my sketch directory and ran make.  The result:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">/bin/sh: /usr/share/arduino-0017/hardware/cores/arduino/Print.d: Permission denied
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">There are some comments in the ebuild about this -- apparently the IDE builds the <tt>.d</tt> files when it is first run, using group id <tt>uucp</tt>.  The easiest fix was just to run make as root, once, to build these files.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The Makefile references <tt>wiring_serial.c</tt>,
 but this file is not present in the distribution.  I removed it from 
the Makefile.  Presumably I'll be on my own to configure serial I/O?</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I'm 
starting to get the impression that using the IDE is the smart way to go
 here!  The next error is from the linker, unable to find its script:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">/usr/libexec/gcc/avr/ld: cannot open linker script file ldscripts/avr5.x: No such file or directory
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This is <a href="http://bugs.gentoo.org/show_bug.cgi?id=147155">Gentoo bug #147155</a>, which at the moment is not fixed.  The workaround:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">ln -s /usr/lib/binutils/avr/2.20/ldscripts /usr/avr/lib/ldscripts
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">And finally, we have a build:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">dustin@erdos ~/tmp/Blink $ make
# Here is the "preprocessing".
# It creates a .cpp file based with the same name as the .pde file.
# On top of the new .cpp file comes the WProgram.h header.
# At the end there is a generic main() function attached.
# Then the .cpp file will be compiled. Errors during compile will
# refer to this new, automatically generated, file.
# Not the original .pde file you actually edit...
test -d applet || mkdir applet
echo '#include "WProgram.h"' &gt; applet/Blink.cpp
cat Blink.pde &gt;&gt; applet/Blink.cpp
cat /usr/share/arduino-0017/hardware/cores/arduino/main.cxx &gt;&gt; applet/Blink.cpp
/usr/bin/avr-gcc -mmcu=atmega168 -I. -gstabs -DF_CPU=16000000 -I/usr/share/arduino-0017/hardware/cores/arduino -Os -Wall -Wstrict-prototypes -std=gnu99  -o applet/Blink.elf applet/Blink.cpp -L. applet/core.a -L/usr/avr/lib -lm
cc1plus: warning: command line option "-Wstrict-prototypes" is valid for Ada/C/ObjC but not for C++
cc1plus: warning: command line option "-std=gnu99" is valid for C/ObjC but not for C++
/usr/bin/avr-objcopy -O ihex -R .eeprom applet/Blink.elf applet/Blink.hex


   text    data     bss     dec     hex filename
      0    1244       0    1244     4dc applet/Blink.hex
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">running <tt>make upload</tt> as root, right after pressing the reset button in the board, successfully uploads the program.  Blinkies!</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Cleanup</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">A few
 small changes will make a lot of this easier.  First, I want to make 
sure that the USB device is writable by a non-root user, using udev.  
First, I used the following command to get the udev identifying 
information for the device.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">udevadm info --attribute-walk -n /dev/ttyUSB0
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
identifiers for the device are given from most-specific to 
least-specific.  The device itself doesn't have much to identify it:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">  looking at device '/class/tty/ttyUSB0':
    KERNEL=="ttyUSB0"
    SUBSYSTEM=="tty"
    DRIVER==""
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">but I need something to match on this device, so I used <tt>SUBSYSTEM=="tty"</tt>.  To avoid confusion with other tty devices, though, I needed something more specific.  Looking at the parent entry, I see</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">    ATTRS{interface}=="FT232R USB UART"
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">which looks like a good identifier for this component.  Aside from setting the ownership and permissions, I decided to add a <tt>/dev/avr</tt> symlink, too.  The completed rule is:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">SUBSYSTEM=="tty", ATTRS{idVendor}=="0403", ATTRS{idProduct}=="6001" GROUP="users", MODE="0666", SYMLINK+="avr"
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The first three fields match the device using the numbers from <tt>lsusb</tt>, and the last three set the proper group-id, mode, and dev-tree symlink for the device.  I put this rule in <tt>/etc/udev/rules.d/10-user.rules</tt> and updated udev:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">udevadm trigger
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">sure enough, <tt>/dev/avr</tt> now exists.  I added this path as the <tt>PORT</tt> in the Makefile.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
second problem is that the makefile is not smart enough to reset the 
unit before uploading.  That's easily fixed, using a variant of the <tt>pulse</tt> script from above, by adding a perl invocation to the Makefile (don't forget the whitespace must be a tab character!):</p>



<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Finally, I commented out the value of <tt>CDEBUG</tt> in the Makefile, as I don't see any real utility for debug symbols on a microcontroller.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Summary</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
turned out to be a lot of work -- the Arudino developers have done a 
good job of encapsulating a lot of complexity in a nice, easy-to-use 
IDE.  But now I can use my usual editor and workflow to develop programs
 for the ATMEGA328P, and that means a lot to me!</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/35-Charlieplexing-watch-your-voltage-levels%21.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Charlieplexing: watch your voltage levels!</span></a><div class="lastUpdated">January 30, 2010 9:58 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><a href="http://en.wikipedia.org/wiki/Charlieplexing">Charlieplexing</a> is a technique to allow <i>n</i> tristate digital output pins to control <i>n(n-1)</i> LEDs, by exploiting the high-impedence state of the output pins and the reverse-bias tolerance of LEDs.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I put together a circuit to test this out, similar to the 6-LED diagram in the <a href="http://en.wikipedia.org/wiki/Charlieplexing#Expanding:_tri-state_logic">Wikipedia entry</a>.  I added three 220 resistors, though.  This ASCII art sums it up nicely:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">      +---&gt;|---+          +---&gt;|---+          +---&gt;|---+    
      |  LED1  |          |  LED3  |          |  LED5  |
 &lt;----|        |-/\/\-+---|        |-/\/\-+---|        |-/\/\-+--&gt;
      |  LED2  |      |   |  LED4  |      |   |  LED6  |      |   
      +---|&lt;---+      R   b---|&lt;---+      G   +---|&lt;---+      B   
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">where
 R, G, and B are the three connections to the Arduino, and the arrows on
 the left and right side are joined by a jumper.  I put together some 
simple Arduino-level code to drive this layout in a simple counter 
sequence, and fired it up.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">One thing I will say about the Arduino: <a href="http://diveintomark.org/archives/2010/01/29/tinkerers-sunset">tinkering</a>
 pays off.  After the usual forgotten-semicolon cleanup, LEDs started 
blinking immediately.  This is good, because I don't have much of an 
Arduino-debugging toolbox at this point!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Anyway,
 there's a problem.  When an LED is fully illuminated, two other LEDs 
glow at about 50% brightness.  For example, when LED1 is on, LED4 and 
LED6 glow too.  It's not hard to see why: to turn LED1 on, the arduino 
drives R low and B high.  The path through LED1 is intended, but LED4 
and LED6 are also forward-biased in series, albeit with more resistance 
inline and the voltage-drop from two LEDs.  Can this be prevented?</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Let's work out the math here, using the resistance <i>r</i> as the only parameter I can change.  The LEDs I'm using (<a href="http://www.sparkfun.com/commerce/product_info.php?products_id=9592">5mm Green LEDs from CHINA YOUNG SUN</a>)
 don't have a lot of performance data, but do list a forward voltage 
drop of 1.8-2.2V, so let's use 2V.  My Arduino is running from the USB 
power at 5V.  The resistor to the left of R defines the current through 
that leg for the remaining <i>5-2 = 3V</i>, so <i>I<sub>1</sub></i> is <i>3/r</i>.  On the leg containing LED4 and LED6 a total of 1V remains across two resistors, so <i>I<sub>4</sub></i> and <i>I<sub>6</sub></i> are both <i>1/2r</i>.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
LED datasheet lists a maximum average current (20ma) and peak current 
(30ma), but doesn't list a minimum current.  Guessing 1ma, I need <i>1/2r &lt; 0.001</i>, so <i>r &gt; 500</i>.  At that point, though, <i>I<sub>1</sub></i>
 is just 6ma - not nearly bright enough to impress, particularly with a 
16% duty cycle when multiplexing all 6 LEDs.  All the same, I figured 
I'd try it.  The closest resistor I had was 470, so I gave that a shot.
  The result was bad on all fronts: the expected LED is dim, and the 
unwanted LEDs are still visible.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
suspect that, to get this to work, I'd need to reduce the supply voltage
 to something less than twice the LEDs' forward voltage drop.  Then two 
LEDs in series would carry no current.  I considered doing this with a 
simple voltage divider on each microcontroller pin, but this of course 
ruins the tri-state behavior that's critical to charlieplexing.  I could
 build that by using two transistors for each pin, but by that point the
 benefits of charlieplexing in terms of component count are long lost.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So, in short, for good charlieplexing, make sure that your source voltage is less than twice the <i>V<sub>f</sub></i> of your LEDs.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><i>[EDIT:
 it turns out, after some futzing that this also "works fine" if you 
just leave out the ballast resistors.  Presumably this relies on a 
limited duty cycle and a "high enough" internal resistance to not melt 
the LEDs]</i> </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/37-Revising-the-allowForce-option.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Revising the allowForce option</span></a><div class="lastUpdated">February 13, 2010 4:08 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Buildbot's WebStatus display has, for a long time, had an <tt>allowForce</tt>
 option which controls what kind of mayhem can be wrought via the web 
interface.  Historically, this has been a boolean option: either web 
users can do everything (force builds and shut down slaves) or nothing. 
 <a href="http://buildbot.net/trac/ticket/701">Bug 701</a> asks that we change that to give more granular access control.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Buildbot
 has an interesting way of separating the status display from the 
control functionality.  It has two parallel interface hierarchies, 
IStatus and IControl, implementing the necessary methods.  The IStatus 
hierarchy is illustrated with the orange bubbles here:</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><img width="80%" alt="" src="codevigorous_files/status.html" /></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The IControl hierarchy is similar, although it only goes down to the Build level right now.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">When <tt>allowForce</tt> is true, the WebStatus object adapts the buildmaster to the IControl interface and adds a link to the result in its <tt>control</tt>
 attribute.  Forcing a build or shutting down a slave then uses this 
object to navigate to the appropriate control object and calls a method 
from the corresponding interface.  If the <tt>control</tt> attribute is None, no access is allowed.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This scheme has the advantage that it is difficult to accidentally expose functionality, since when <tt>allowForce</tt>
 is false, the control methods are inaccessible.  However, it has the 
disadvantage of not allowing any more granular level of access control.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I <a href="http://github.com/djmitche/buildbot/commit/7572c5bdad4a09393b665fff2939e605df58deb1">just reworked</a>
 the web status to have a more flexible authorization mechanism, and 
while I wasn't able to remove the IControl hierarchy entirely, I was 
able to marginalize it to only those code blocks that need to perform 
controlled actions, instead of passing control objects all over the 
place. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/38-Testing-Legacy-Code.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Testing Legacy Code</span></a><div class="lastUpdated">February 17, 2010 1:26 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I just read Roy Osherove's <a href="http://www.amazon.com/Art-Unit-Testing-Examples-Net/dp/1933988274">The Art of Unit Testing with Examples in .NET</a>,
 on the advice of a slashdot review.  I was not terribly impressed with 
the book, but reading it did help me to solidify my thinking about 
testing and test-driven development, and put words to concepts I had 
come to on my own.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Rather late in the book, Osherove describes three properties of good tests. 
</p><ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li><i>Trustworthiness</i> - Do developers believe that passing tests 
mean things are working? Do developers believe that failing tests 
indicate a real bug?</li>
<li><i>Maintainability</i> - Do developers think that tests are easy to add and maintain, or are they likely to avoid writing tests when rushed?</li>
<li><i>Readability</i> - Do developers often consult the unit tests to see how the system under test is supposed to work?</li>
</ul><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What 
most struck me was that these properties were related to developers' 
perceptions of the tests, not the tests themselves.  Tests are as much a
 social artifact of a project as a technical tool.</p><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">

</p><h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Buildbot's Tests</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Around
 the time I was reading this, one of the more prolific Buildbot 
contributors commented, "I try not to change the tests - they scare me."
  Buildbot's tests were badly isolated, slow, and failed intermittently.
  As maintainer, I had grown accustomed to saying "oh, that test fails 
sometimes, don't worry about it" - a trustworithiness failure.  Because 
of the terrible isolation, changing just about anything in Buildbot 
would cause dozens of tests to fail, requiring repetitive editing to fix
 - not maintainable.  And the tests consisted of long sequences of 
operations and assertions, written in the Twisted style, which is 
already not readable.  As a result, even I don't know what most of the 
tests are actually testing.  This was a bad situation for any 
application, but particularly embarassing for a popular testing tool!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So I <b>blew the tests away</b>.  Well, not really - I moved them to <tt>buildbot/broken_test/</tt> in hopes they can be useful in writing new tests, and so that the braver souls among us can still run them.  Now our <a href="http://buildbot.net/metabuildbot/tgrid">metabuildbot</a> is green, and I can legitimately ask for unit tests for new code.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">There
 are costs associated with this move, too. A lot of people have worked 
very hard to write tests that have now been categorically labeled 
"broken," to whom all I can say is "I'm sorry".  With far fewer tests 
and thus far worse coverage, it's also difficult to have confidence that
 Buildbot really works.  The short-term workaround is to make a few <a href="http://comments.gmane.org/gmane.comp.python.buildbot.devel/5703">beta releases</a> and rely on real-world testing to suss out any problem.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So 
this is only the first step.  We - I - still need to write real tests 
for the vast majority of the Buildbot code.  That's particularly 
complicated because Buildbot's units are badly isolated, and interfaces 
are ill-defined.  I will need to do a good bit of refactoring to bring 
it into compliance.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/39-Solving-an-Encoding-Mystery.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Solving an Encoding Mystery</span></a><div class="lastUpdated">March 15, 2010 11:52 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I don't write about it here, but I've been getting into brewing beer.  I downloaded an app for my iPhone, <a href="http://www.ibrewmaster.com/iBrewMaster/Welcome.html">iBrewMaster</a>, which helps me store recipes and track batches of homebrew through the brewing, fermeting, and serving stages.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I recently decided to make a clone of Dogfish Head's <a href="http://www.dogfish.com/brews-spirits/the-brews/year-round-brews/raison-detre.htm">Raison D'tre</a>.
  This beer is fantastic, but that's beside the point.  I added the 
recipe to the app, and clicked save.  In the menu, however, I saw 
"Raison D'tre".  Not pretty.  The app has a feature where you create a
 "batch" from a particular recipe.  I did so, and the name of the batch 
appeared as "Raison D'tre".  Even worse!
 I emailed the app developer, who replied almost immediately regarding 
how he was handling encodings.  I won't go into detail, except to say 
that he is careful to always encode strings before inserting them into 
the internal SQLite database.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
wanted to give him more information than a simple "well, it doesn't work
 and you should fix it!"  So I set about trying to replicate this 
particular sequence of characters.  I know that Macs (and the iPhone is a
 Mac) have good support for encodings, so I assume the UI is not at 
fault.  I know that the strings go into SQLite in UTF-8, and that SQLite
 just treats them as bytestrings, so a later SELECT will return the same
 UTF-8 bytestring as was specified in the INSERT.  So the error must 
occurr somewhere between the SELECT and displaying the string on-screen.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Character Encodings</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">A 
word about encodings, with a bit of revisionist history.  In the 
beginning, there was the Unicode Character Set.  Every funny squiggle 
that the monks knew how to make on paper had a number - its Unicode 
codepoint.  There are a <i>lot</i> of Unicode characters - <a href="http://www.i18nguy.com/unicode/char-count.html">95156</a> at last count.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Then 
computers were invented, and we needed to represent, or encode, these 
squiggles in only 7 bits each.  Someone (who probably only spoke 
English) decided "well, you can only use the first 127 characters," and 
thus ASCII was born.  If you want to write an "" in ASCII, you'll have 
to make do with "n".  Don't even ask about "".  We soon got a bit less 
stingy (get it?), and with 8 bits available, everyone rushed to put 
their favorite characters at code points 128-255 - regardless of what 
Unicode put there.  For example, in latin-1, "" is at code point 240.  
On a Mac, it's 150.  Trying to decode a byte in the range 128-255 was a 
challenge, because the encoding was usually unknown.  Those were dark 
days, as chaos reigned.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Finally, some enlightened souls (Rob Pike and Ken Thompson) scratched out a new encoding <a href="http://www.cl.cam.ac.uk/%7Emgk25/ucs/utf-8-history.txt">on a placemat</a>.
  In this encoding, called UTF-8, all of the 7-bit ASCII characters 
still fit in one byte, and look exactly the same.  But all of the other 
characters take more than one byte, with some cleverness applied to make
 the encoding both compact and easy to decode reliably.  As a side note,
 the Unicode characters 128-255 match the latin-1 character set.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Now, if you have a sequence of unicode characters, say "" that you want to store digitally, then you need to <i>encode</i>
 them, preferably in UTF-8, with the result being a bytestring.  When 
you want the unicode characters back (perhaps to do some hyphenation), 
you perform the reverse operation, and <i>decode</i> from UTF-8 to Unicode Characters.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Back to the Chase</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">A common mistake with multi-byte encodings is to assume that each byte is a distinct character, perhaps with a <tt>for</tt>
 loop indexing an array of bytes.  Since one character ("") turned into
 two (""), this was a reasonable guess.  A little Python (in my 
Unicode-enabled terminal) shows me the encoded form of "":</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">&gt;&gt;&gt; print `u""` 
u'\xc3\xaa'
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Treating those as Unicode characters instead of bytes is simple:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">&gt;&gt;&gt; print u"Raison D'\u00c3\u00aatre"
Raison D'tre
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">No 
dice.  Another common mistake is to encode with one encoding, and decode
 with another.  This is especially common when the programming 
environment "automatically" performs encodings or decodings.  For 
example, Python has an annoying habit of decoding to ASCII, which 
produces the infamous <tt>UnicodeEncodeError</tt>.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So let's try this out, guessing at the encoding that's used on the way out.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">&gt;&gt;&gt; orig = u"Raison D'tre"
&gt;&gt;&gt; print orig.encode('utf-8').decode('latin-1')
Raison D'tre
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
result is the same as the single-byte treatment above.  Why?  Recall 
that the latin-1 encoding is identical to Unicode in the range 128-255, 
so treating a byte as a Unicode character is the same as treating it as a
 latin-1 character.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">At this point, I perused the list of encodings Python supports, and "mac-roman" jumped out as a potential culprit.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">&gt;&gt;&gt; print orig.encode('utf-8').decode('mac-roman')
Raison D'tre
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">A match!  What about the longer string of nonsense in the batch name?</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">&gt;&gt;&gt; once = orig.encode('utf-8').decode('mac-roman')
&gt;&gt;&gt; print once.encode('utf-8').decode('mac-roman')
Raison D'tre
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Another match.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
don't know much about iPhone internals, but I assume that the string 
library treats a bytestring without any attached encoding as being in 
the Mac-Roman character set.  When the value was selected out of the 
recipes table, this decoding was done implicitly, followed by an 
explicit UTF-8 encoding when inserting into the batches table, and 
another implicit Mac-Roman decoding when selecting the batch for 
display.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/40-Whats-New-in-Amanda-Automated-Tests.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What's New in Amanda: Automated Tests</span></a><div class="lastUpdated">March 12, 2010 1:03 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This is the first in what will be a series of posts about recent work on <a href="http://amanda.org/">Amanda</a>.
  Amanda has a reputation as old and crusty -- not so!  Hopefully this 
series will help to illustrate some of the new features we've completed,
 and what's coming up.  I'll be cross-posting these on <a href="http://www.zmanda.com/blogs/">the Zmanda Team Blog</a> too.</p>

<div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><img src="codevigorous_files/chart.png" /></div>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Among
 open-source applications, Amanda is known for being stable and highly 
reliable.  To ensure that Amanda lives up to this reputation, we've 
constructed an automated testing framework (using <a href="http://buildbot.net/">Buildbot</a>)
 that runs on every commit.  I'll give some of the technical details 
after the jump, but I think the numbers speak for themselves.  The 
latest release of Amanda (which will soon be 3.1.0) has 2936 tests!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">These
 tests range from highly-focused unit tests, for example to ensure that 
all of Amanda's spellings of "true" are parsed correctly, all the way up
 to full integration: runs of amdump and the recovery applications. The 
tests are implemented with Perl's <tt>Test::More</tt> and <tt>Test::Harness</tt>.  The result for the <a href="http://github.com/zmanda/amanda/commit/deb1d40c203906bd949789c4fab08172d54c49cc">current trunk</a> looks like this:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">=setupcache.....................ok
Amanda_Archive..................ok
Amanda_Changer..................ok
Amanda_Changer_compat...........ok
Amanda_Changer_disk.............ok
Amanda_Changer_multi............ok
Amanda_Changer_ndmp.............ok
Amanda_Changer_null.............ok
Amanda_Changer_rait.............ok
Amanda_Changer_robot............ok
Amanda_Changer_single...........ok
Amanda_ClientService............ok
Amanda_Cmdline..................ok
Amanda_Config...................ok
Amanda_Curinfo..................ok
Amanda_DB_Catalog...............ok
Amanda_Debug....................ok
Amanda_Device...................ok
        211/428 skipped: various reasons
Amanda_Disklist.................ok
Amanda_Feature..................ok
Amanda_Header...................ok
Amanda_Holding..................ok
Amanda_IPC_Binary...............ok
Amanda_IPC_LineProtocol.........ok
Amanda_Logfile..................ok
Amanda_MainLoop.................ok
Amanda_NDMP.....................ok
Amanda_Process..................ok
Amanda_Recovery_Clerk...........ok
Amanda_Recovery_Planner.........ok
Amanda_Recovery_Scan............ok
Amanda_Report...................ok
Amanda_Tapelist.................ok
Amanda_Taper_Scan...............ok
Amanda_Taper_Scan_traditional...ok
Amanda_Taper_Scribe.............ok
Amanda_Util.....................ok
Amanda_Xfer.....................ok
amadmin.........................ok
amarchiver......................ok
amcheck.........................ok
amcheck-device..................ok
amcheckdump.....................ok
amdevcheck......................ok
amdump..........................ok
amfetchdump.....................ok
amgetconf.......................ok
amgtar..........................ok
amidxtaped......................ok
amlabel.........................ok
ampgsql.........................ok
        40/40 skipped: various reasons
amraw...........................ok
amreport........................ok
amrestore.......................ok
amrmtape........................ok
amservice.......................ok
amstatus........................ok
amtape..........................ok
amtapetype......................ok
bigint..........................ok
mock_mtx........................ok
noop............................ok
pp-scripts......................ok
taper...........................ok
All tests successful, 251 subtests skipped.
Files=64, Tests=2936, 429 wallclock secs (155.44 cusr + 31.48 csys = 186.92 CPU)
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
skips are due to tests that require external resources - tape drives, 
database servers, etc.  The first part of the list contains tests for 
almost all perl packages in the <tt>Amanda</tt> namespace.  These are 
generally unit tests of the new Perl code, although some tests integrate
 several units due to limitations of the interfaces.  The second half of
 the list is tests of Amanda command-line tools.  These are integration 
tests, and ensure that all of the documented command-line options are 
present and working, and that the tool's behavior is correct.  The 
integration tests are necessarily incomplete, as it's simply not 
possible to test every permutation of this highly flexible package.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The <tt>=setupcache</tt>
 test at the top is interesting: because most of the Amanda applications
 need some dumps to work against, we "cache" a few completed amdump runs
 using tar, and re-load them as needed during the subsequent tests.  
This speeds things up quite a bit, and also removes some variability 
from the tests (there are a <i>lot</i> of ways an amdump can go wrong!).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The entire test suite is run at least 54 times for every commit by <a href="http://buildbot.net/">Buildbot</a>.
  We test on 42 different architectures - about a dozen linux distros, 
in both 32- and 64-bit varieties, plus Solaris 8 and 10, and 
Darwin-8.10.1 on both x86 and PowerPC.  The remaining tests are for 
special configurations -- server-only, client-only, special runs on a 
system with several tape drives, and so on.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/45-Whats-New-in-Amanda-Hackability.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What's New in Amanda: Hackability</span></a><div class="lastUpdated">July 1, 2010 11:29 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">It's been a while since I've posted about recent development in <a href="http://amanda.org/">Amanda</a>, but it's not for lack of interesting topics!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Today
 I want to talk a little bit about Amanda's development.  Historically, 
Amanda has always had a small, core group of developers who do the 
lion's share of the development work.  There are probably lots of 
reasons for this, not least of which is that a backup application isn't 
the sexiest project on which to spend your spare time.  But I think 
there's a deeper reason, and it has to do with hackability.
 Amanda was originally written in C, which means any changes require the
 full set of developer tools.  For example, just to fix a typo in an 
error message, you would need to find the source, configure and compile 
it, find and fix the error message, and recompile to test.  Fixing 
something more substantial in the highly interdependent Amanda codebase 
also requires a deep understanding of many parts of Amanda - from the 
obscure configuration interface to the oddly interlinked disklist 
structure.  This level of programming skill is not common among Amanda's
 user base (systems administrators), and I can count the people who 
understand the disklist structure on one hand.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
result has been a paltry flow of patches from anyone but the core 
hackers.  Furthermore, no entry path has been available by which 
newcomers could work their way up to being core developers.  While I 
don't want to disparage the work of any of the great programmers who 
have written Amanda over the years, it's a shame that there have been so
 few at any time, and I worry about what would happen if the number were
 to reach zero.  So what to do?</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">$hackability++</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">We've
 done a few things to try to make Amanda more hackable.  Probably the 
biggest change is to rewrite parts of Amanda in Perl.  I'm asked "why" 
quite often, and while we had a lot of reasons, two relate directly to 
hackability.  First, more sysadmins know Perl than C, because Perl is 
quite often used to build the "glue" that links systems together.  
Interestingly, based on many conversations, it seems that Python may 
also have been a good choice, as I <a href="http://code.v.igoro.us/archives/12-Perl-vs.-Python.html">suspected when I first proposed the rewrite</a>.  But it's too late now!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Second, and more importantly, Perl code can be hacked in place.  If <a href="http://wiki.zmanda.com/man/amvault.8.html">amvault</a> isn't acting the way you want it to, just open up <tt>/usr/sbin/amvault</tt>
 and tweak away.  No need to download the source, no need to compile, no
 segmentation faults, just hacking.  When you're done, run a quick <tt>diff</tt> and send the results to amanda-hackers.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Even users who do not know Perl can take advantage of this <i>in-situ</i>
 hackability.  Within Amanda's C code, if I want a user to try a patch, 
that user must figure out how to download Amanda's source, apply the 
patch, configure, compile, and install.  None of those steps are 
trivial.  With Perl code, I can often provide a patch that is simple 
enough to be applied directly to the installed executables by hand, or 
with a simple application of <tt>patch</tt>.  Everyone stays focused on the bug under investigation, and the user's backups are up and running that much more quickly.</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">New APIs</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">As I 
mentioned before, historically Amanda's code has been highly 
interdependent.  Details of the implementation of the holding disk were 
spread over most of the files in the server implementation.  The 
dumplevel -987 has a special meaning that is documented nowhere, but 
referenced in several source files.  All of this makes new development 
difficult, because it's impossible to "slice off" and study a portion of
 Amanda in isolation.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
solution here is to create abstract interfaces, where new functionality 
can be "plugged in" and Amanda can use it without changes.  The Amanda 
developers have abused the term "API" for these interfaces, and we now 
have quite a few:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li><a href="http://wiki.zmanda.com/index.php/Application_API">Application API</a> - an abstraction of backup clients, e.g., <a href="http://code.v.igoro.us/archives/50-Whats-New-in-Amanda-Postgres-Backups.html">ampgsql</a> for Postgres;
</li><li><a href="http://wiki.zmanda.com/index.php/Device_API">Device API</a> - an abstraction of backend storage devices, such as tape, disk, cloud, or DVD-RW;
</li><li><a href="http://wiki.zmanda.com/index.php/Changer_API">Changer API</a> - an abstraction of tape changers and other mechanisms for selecting from a set of volumes; and
</li><li><a href="http://wiki.zmanda.com/index.php/Script_API">Script API</a> - a means of invoking scripts before or after certain events during a backup.
</li></ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
strategy has already paid off: we have seen several new scripts and 
applications contributed, and the DVD-RW device arrived out of the blue 
as a contribution from someone who found it useful.</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Other Changes</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In the interest of greater accessibility to new hackers, we have also put Amanda on <a href="http://github.com/zmanda/amanda">github</a> and created a set of good "beginner" projects.  Zmanda has even offered to <a href="http://code.v.igoro.us/archives/53-Want-to-work-on-Amanda.html">pay people to hack on Amanda</a>,
 as a way of easing the cost of entry.  I also try to point out 
interesting projects on the Amanda mailing list, particularly projects 
that Jean-Louis and I probably will not find time to work on.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
idea here is to encourage new hackers to pick up a well-scoped project 
to become familiar with Amanda.  The hackers can then move on to more 
sophisticated projects that meet their particular backup needs or 
address a particular interest.</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Will You Join Me?</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So Amanda is ready for you.  When can you start?</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/49-Whats-New-in-Amanda-Transfer-Architecture.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What's New in Amanda: Transfer Architecture</span></a><div class="lastUpdated">March 12, 2010 3:06 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Amanda's
 primary mission in life is to move large quantities of data around.  
Historically, this has been done through a patchwork of methods, each 
written separately and with its own quirks.  POSIX pipes, TCP sockets, 
shared memory, on-disk cache files -- Amanda's done it all.  But these 
multiple implementations were error-prone, difficult to maintain, and 
often not the most efficient approach.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In an effort to remedy this, we introduced the <a href="http://wiki.zmanda.com/index.php/Transfer_Architecture">transfer architecture</a>, abbreviated XFA.  This was technically included in Amanda-2.6.1, but was only used by <i>amvault</i>.
  In the upcoming Amanda-3.1 release, however, the XFA is central to all
 recovery operations, and is used internally by the taper (the portion 
of the backup system that writes to devices).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This post highlights some of the features of the transfer architecture, and some of the improvements we'd like to make. </p><h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Transfers and Elements</h2>
A transfer is pretty simple: it moves data from one place to another.  
It is built from a list of transfer elements, the first being the data 
source and the last the destination.  Any elements in the middle are 
filters, and could apply compression or encryption, for example.  
Elements are automatically connected to one another using the most 
efficient means available.<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Transfers operate <i>asynchronously</i>,
 meaning that ordinary execution of Amanda continues in parallel to the 
movement of data.  When the transfer needs Amanda's attention, it sends a
 message, and Amanda reacts accordingly.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The beauty of this architecture is in the variety of elements that can be connected.</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>Sources
<ul>
<li>File or socket</li>
<li>DirectTCP Connection</li>
<li>Holding Disk</li>
<li>Spanned dumpfile</li>
<li>Random or repeated patterns (for testing)</li>
</ul></li>
<li>Filters
<ul>
<li>In-process compression or encryption (e.g., libgz)</li>
<li>External utilities (e.g., gzip or amgpgcrypt)</li>
</ul></li>
<li>Destinations
<ul>
<li>File or socket</li>
<li>DirectTCP Connection</li>
<li>Spanned Dumpfile</li>
</ul>

<p></p></li></ul><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The full list is given <a href="http://wiki.zmanda.com/pod/Amanda/Xfer.html">in the POD</a>.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Benefits</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
advantage of the transfer architecture is that it massively simplifies 
the process of transferring data.  Nowhere is this more obvious than in 
the splitting and re-joining of dumpfiles.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The <i>Amanda::Xfer::Recovery::Source</i> element, which reads from spanned dumpfiles, cooperates with the <i><a href="http://wiki.zmanda.com/pod/Amanda/Recovery/Clerk.html">Clerk</a></i>,
 via transfer messages, to load the proper volumes and seek to the 
proper files to recover and entire dumpfile, even if it is distributed 
over more than one source volume.  Similarly, <i>Amanda::Xfer::Taper::Dest</i> works with a <i><a href="http://wiki.zmanda.com/pod/Amanda/Taper/Scribe.html">Scribe</a></i> to load volumes and update the catalog while spanning dumpfiles.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So 
the Amanda taper is a simple wrapper around a transfer from holding disk
 (FILE-WRITE) or socket (PORT-WRITE) to a spanned dumpfile, using a 
scribe.  Similarly, all of the recovery tools use a clerk and a transfer
 to read dumpfiles off the appropriate volumes.  And <a href="http://wiki.zmanda.com/man/amvault.8.html">amvault</a> combines the two to simultaneously read from one volume and write to another.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Future</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">At 
this point, the transfer architecture is a reliable abstraction, but it 
is not yet terribly efficient.  The advantage of the abstraction, 
though, is that as it is made more efficient, all of the components of 
Amanda that make use of it will immediately become faster, with no 
changes.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">There
 are plenty of places in Amanda where the transfer architecture will be 
useful, and certainly plenty of work to do to make it faster.  If you're
 interested in helping out, please let me know!</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/50-Whats-New-in-Amanda-Postgres-Backups.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What's New in Amanda: Postgres Backups</span></a><div class="lastUpdated">March 25, 2010 7:53 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In the second installment a series of posts about recent work on <a href="http://amanda.org/">Amanda</a>.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
Application API allows Amanda to back up "structured" data -- data that 
cannot be handled well by 'dump' or 'tar'.  Most databases fall into 
this category, and with the 3.1 release, Amanda ships with <tt><a href="http://wiki.zmanda.com/man/ampgsql.8.html">ampgsql</a></tt>, which supports backing up <a href="http://www.postgresql.org/">Postgres</a> databases using the software's <a href="http://www.postgresql.org/docs/current/static/continuous-archiving.html">point-in-time recovery</a> mechanism.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The how-to for this application is <a href="http://wiki.zmanda.com/index.php/How_To:Use_Amanda_to_Back_Up_PostgreSQL">on the Amanda wiki</a>. </p><h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Operation</h2>
Postgres, like most "advanced" databases, uses a logging system to 
ensure consistency even in the face of (some) hardware failures.  In 
essence, it writes every change that it makes to the database to the 
logfile <i xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">before</i>
 changing the database itself.  This is similar to the operation of 
logging filesystems.  The idea is that, in the face of a failure, you 
just replay the log to re-apply any potentially corrupted changes.<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Postgres
 calls its log files WAL (write-ahead log) files.  By default, they are 
16MB.  Postgres runs a shell command to "archive" each logfile when it 
is full.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So there are two things to back up: the data itself, which can be quite large, and the logfiles.  A full backup works like this:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>Execute <tt>PG_START_BACKUP(ident)</tt> with some unique identifier.</li>
<li>Dump the data directory, excluding the active WAL logs.  Note that 
the database is still in operation at this point, so the dumped data, 
taken alone, will be inconsistent.</li>
<li>Execute <tt>PG_STOP_BACKUP()</tt>.  This archives a text file with the suffix <tt>.backup</tt> that indicates which WAL files are needed to make the dumped data consistent again.</li>
<li>Dump the required WAL files</li>
</ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">An incremental backup, on the other hand, only requires backing up the already-archived WAL files.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">A 
restore is still a manual operation -- a DBA would usually want to 
perform a restore very carefully.  The process is described on the wiki 
page linked above, but boils down to restoring the data directory and 
the necessary WAL files, then providing postgres with a shell command to
 "pull" the WAL files it wants.  When postgres next starts up, it will 
automatically enter recovery mode and replay the WAL files as necessary.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Quiet Databases</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">On older Postgres versions, making a full backup of a quiet database is actually impossible.  After <tt>PG<em>STOP</em>BACKUP()</tt>
 is invoked, the final WAL file required to reconstruct a consistent 
database is still "in progress" and thus not archived yet.  Since the 
database is quiet, postgres does not get any closer to archiving that 
WAL file, and the database hangs (or, in the case of ampgsql, times 
out).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Newer versions of Postgres do the obvious thing: <tt>PG<em>STOP</em>BACKUP()</tt> "forces" an early arciving of the current WAL file.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
best solution for older versions is to make sure transactions are being 
committed to the database all the time.  If the database is truly silent
 during the dump (perhaps it is only accessed during working hours), 
then this may mean writing garbage rows to a throwaway table:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">CREATE TABLE push_wal AS SELECT * FROM GENERATE_SERIES(1, 500000);
DROP TABLE push_wal;
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Note that using <tt>CREATE TEMPORARY TABLE</tt> will not work, as temporary tables are not written to the WAL file.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">As a brief encounter in <tt>#postgres</tt> taught me, another option is to upgrade to a more modern version of Postgres!</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Log Incremental Backups</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">DBAs 
and backup admins generally want to avoid making frequent full backups, 
since they're so large.  The usual pattern is to make a full backup and 
then dump the archived log files on a nightly basis for a week or two.  
As the log files are dumped, they can be deleted from the database 
server, saving considerable space.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In 
Amanda terms, each of these dumps is an "incremental", and is based on 
the previous night's backup.  That means that the dump after the full is
 level 1, the next is level 2, and so on.  Amanda currently supports 99 
levels, but this limit is fairly arbitrary and can be increased as 
necessary.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
problem in ampgsql, as implemented, is that it allows Amanda to schedule
 incremental levels however it likes.  Amanda considers a level-<i>n</i> backup to be everything that has changed since the last level-<i>n-1</i> backup.  This works great for GNU tar, but not so well for Postgres.  Consider the following schedule:</p>

<table xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<tbody><tr><th>Monday</th><td>level 0</td></tr>
<tr><th>Tuesday</th><td>level 1</td></tr>
<tr><th>Wednesday</th><td>level 2</td></tr>
<tr><th>Thursday</th><td>level 1</td></tr>
</tbody></table>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
problem is that the dump on Thursday, as a level 1, needs to capture all
 changes since the previous level 0, on Monday.  That means that it must
 contain all WAL files archived since Monday, so those WAL files must 
remain on the database server until Thursday.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The fix to this is to only perform level 0 or level-<i>n+1</i> dumps, where <i>n</i>
 is the level of the last dump performed.  In the example above, this 
means either a level 0 or level 3 dump on Thursday.  A level 0 is a full
 backup and requires no history.  A level 3 would only contain WAL files
 archived since the level 2 dump on Wednesday, so any WAL files before 
that could be deleted from the database server.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">[EDIT: replaced "corrupt" with the more accurate "inconsistent"; clarified final example]</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/51-Talk-Twisted-Introduction.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Talk: Twisted Introduction</span></a><div class="lastUpdated">March 22, 2010 10:25 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I'll be giving a <a href="http://pumpingstationone.org/2010/03/psone-presents-a-guided-tour-to-twisted-python/">presentation</a> about <a href="http://twistedmatrix.com/trac">Twisted Python</a> programming tomorrow at <a href="http://pumpingstationone.com/">Pumping Station: One</a> in Chicago.  If you're in the area, you should come by!</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>8pm (doors at 7) at 3354 N Elston</li>
<li>Advance copy of the <a href="http://djmitche.github.com/twisted-intro/">Presentation</a></li>
<li>Video (available after the talk is complete)</li>
</ul></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/52-Happy-Ada-Lovelace-Day.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Happy Ada Lovelace Day</span></a><div class="lastUpdated">March 25, 2010 2:35 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Yesterday, March 24, was Ada Lovelace Day.  I was at <a href="http://pumpingstationone.org/2010/03/lady-ada-lovelace-day-at-psone-tomorrow/">Pumping Station: One</a>,
 and decided to spend an hour or so writing something to honor the first
 computer programmer.  I was feeling singularly uninspired, and googling
 for "Ada Lovelace" didn't turn up anything interesting.  But it did 
give me an idea: write a program that googles for you!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
haven't written much JavaScript lately, but I've heard a lot about the 
work Google's done to provide easy JavaScript libraries and APIs.  I 
thought it'd be interesting to try out some of these APIs.  It was!  I 
hacked up a quick HTML page, using a <a href="http://code.google.com/apis/ajaxsearch/documentation/reference.html#_intro_GSearch">Searcher</a> object, to search for Lovelace images.  Here's the code:</p>



<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
only downside I've found is that even if you request a "large" result 
set, you only get 8 results.  I don't know of a way to get subsequent 
results.  So this really only cycles through a few images.  Still, it 
only took me an hour, and most of that was remembering how to use the 
DOM.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/53-Want-to-work-on-Amanda.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Want to work on Amanda?</span></a><div class="lastUpdated">April 12, 2010 3:04 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I've
 not made any secret of the fact that I want more people hacking on 
Amanda.  This is both for selfish reasons -- many hands make light work 
-- and for altruistic reasons -- a broader community of developers can 
provide better governance for the project and long-term continuity.  
With a few noticable exceptions, I haven't had a lot of satisfaction.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
think part of the reason is that Amanda has a steep learning curve, even
 within the new Perl code.  The time to climb that curve is a big 
investment, and folks with only a small itch to scratch can't afford it.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In an
 effort to sweeten the pot, we (Zmanda) are offering to pay for flexible
 work on Amanda.  Part-time or full-time, on your own schedule.  Your 
choice of projects.  Support and gratitude from the other hackers.  And 
the option to become a full Zmanda employee if that's your bent.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Here are some possible projects, to pique your interest:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>MySQL application (to round out the set with <tt><a href="http://code.v.igoro.us/archives/50-Whats-New-in-Amanda-Postgres-Backups.html">ampgsql</a></tt>)</li>
<li><a href="http://cyrusimap.web.cmu.edu/">Cyrus Imapd</a> application (gnutar doesn't deal well with the application's tiny files and hard links)</li>
<li>OpenSSL for network transport, using certificates and keys for authentication</li>
<li>Database-backed backup catalog</li>
<li>Amvault upgrade</li>
<li>Handle Logical EOM (LEOM) on all devices that support it, drastically reducing the number of parts Amanda writes</li>
<li>Support for more cloud backends than just S3</li>
<li>Parallel writes to multiple devices</li>
</ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">If you're interested, contact me (<tt>dustin@zmanda.com</tt>) and we'll work something out! </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/55-LCD-Display-and-TMP102-sensor.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">LCD Display and TMP102 sensor</span></a><div class="lastUpdated">April 17, 2010 10:22 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">It is <i>incredibly</i>
 easy to throw things together with an Arduino.  It's common to see 
criticism of the device when it's used in in projects that don't require
 even a fraction of its power, and that might be justified.  As a 
flexible platform for test-driving complex modules, though, the Arduino 
hits the mark perfectly on flexibility and usability.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
don't have a particular project in mind for my Arduino, but since I 
don't have a multimeter or an oscilloscope, I want to use it as a test 
harness for various basic components as I experiment with them.  To this
 end, I bought a cute <a href="http://www.sparkfun.com/commerce/product_info.php?products_id=9054">16x2 character amber LCD display</a>.  With thoughts of building a fermentation-temperature monitor and learning about the I<sup>2</sup>C bus, I also bought a relatively cheap <a href="http://www.sparkfun.com/commerce/product_info.php?products_id=9418">TMP102 and breakout board</a>.  With a little bit of reading, I was able to stitch them together quickly and easily.
 </p><h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">LCD Display</h2><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
display I purchased is command-driven via a 4-bit parallel port.  It's a
 ST7066, compatible with HD44780.  There are two datasheets available --
 one for the <a href="http://www.sparkfun.com/datasheets/LCD/st7066.pdf">ST7066</a>, and one for the <a href="http://www.sparkfun.com/datasheets/LCD/ADM1602K-NSA-FBS-3.3v.pdf">assembled board</a>.
  The latter adequately described the pinout through unattributed 
copying from the former, but was otherwise useless.  "Qiu", "Chen", and 
"Ye", all three of whom helpfully signed the cover page, should be 
ashamed.  Anyway, here's a brief description of the pins and some more 
details I culled from the ST7066 datasheet:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>V<sub>ss</sub> (ground) and V<sub>dd</sub> (positive supply): these are rated up to 7V, so running from the Arduino's 5V supply is great.</li>
<li>V<sub>0</sub> sets the LCD contrast.  Short on jumpers, I initially 
assumed I could leave this unconnected to get "reasonable" contrast.  
Not so!  I tried setting up a few voltage dividers to get the right 
contrast, without any luck.  Plan to add a 10k pot between ground and 
the positive supply, and tie the wiper to this pin.</li>
<li>RS (register select) selects whether an operation is to configuration registers (0) or RAM (1)</li>
<li>R/W (read/write) selects whether an operation reads or writes to the device</li>
<li>DB0-DB7 is the data bus</li>
<li>E (enable), strobed to move a byte across the data bus</li>
<li>LED+/LED- supply power to the LED backlight, and can be wired directly to the 5V supply.</li>
</ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
Arduino has a lot of digital pins, but all the same it's handy to save a
 few pins.  The display supports reading character and font data, but 
that's not much use: the Arduino can remember whatever it needs to.  So 
we won't need the R/W pin, and can tie it to ground (read) instead.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
display can operate in two data lengths (controlled by the DL 
configuration bit).  In the default mode, only 4 bits (DB4-DB7) on the 
parallel bus are used.  The display starts in 8-bit mode, but 
fortunately the DL bit comes in at pin DB4, so it's relatively easy to 
reset the data length with only 4 pins connected.  Note that there's an 
odd sequencing required here, where you need to set 8-bit mode three 
times <i>before</i> setting 4-bit mode.  Don't worry, though: the Arduino <i>LiquidCrystal</i> library takes care of that for you.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So 
aside from pins tied to V+ or GND, we only need 6 digital I/O pins.  
It's best to avoid the pins that have other functions on the Arduino: 0 
and 1 are RS-232 I/O, and 13 is the onboard LED.  I used pins 2-5 for 
the data bus, pin 12 for E, and pin 13 for RS, since that was at the top
 of the LiquidCrystal example.  V<sub>ss</sub>, LED-, and R/W go to GND; V<sub>dd</sub> and LED+ go to the 5V supply; and V<sub>0</sub> is wired as described above.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">From there on out, it's a straightforward application of the <i>LiquidCrystal</i> library:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">#include &lt;LiquidCrystal.h&gt;

LiquidCrystal lcd(12, 11, 5, 4, 3, 2); 

void setup() {    
    lcd.begin(16, 2); 
}

void loop() {
    lcd.setCursor(0, 0);
    lcd.print("Hello, World");
}
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Note 
that the display itself is capable of a number of interesting things not
 supported by the library.  It has an 80-byte character memory, and can 
scroll that through the display without rewriting the entire screen 
every time.  It can also accept 8 custom 5x11 glyphs, making rudimentary
 animation possible.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">TMP102</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
TMP102 is ridiculously tiny - smaller than the SMD resistors that 
Sparkfun has placed around it on the breakout board.  It senses 
temperature internally, which means it's basically monitoring the 
temperature of its leads.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The device speaks I<sup>2</sup>C (also known as the two-wire interface or SMBus), which makes it pretty easy to connect to the Arduino.  The MCU speaks I<sup>2</sup>C
 via hardware, so the corresponding Arduino library doesn't even need to
 bit-bang the data.  On the Duemilanove, it uses analog-in pin 4 for SDA
 and analog-in pin 5 for SCL.  You'll also need to hook up V+ to the <b>3.3V pin</b>
 on the Arduino (the device is only specified for 3.6V) and GND to the 
TMP102's GND.  Finally, the TMP102's ADD0 pin can cleverly select one of
 four addresses for the device by tying it to one of these four pins.  I
 tied it to GND, giving address 0b1001000.  ALARM is an output pin, so 
you can leave it unconnected.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
TMP102 is a very nice low-power device that's designed to handle several
 common tasks without any interaction from the MCU - it can trigger an 
interrupt when the temperature strays from a configured boundaries, poll
 temperature on a relatively slow schedule, or even poll on command.  I 
didn't use any of that, relying on the device to simply sample the 
temperature on its own schedule.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
TMP102 has four registers, but we'll only use one -- temperature (0b01).
  Like many devices, this one multiplexes addresses and data over the 
same bus.  To read a register, you first select the register by writing 
it to the device, then read the 16-bit value, again with the MSB first. 
 Once a register is selected, it can be read multiple times.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
device's temperature register contains a two's-complement 12-bit value, 
left-aligned, where 0x7FF is 128C; equivalently, a change of one unit 
in the 12-bit value is equivalent to 0.0625C.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Putting it Together</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The obvious combination of these tools is to display the ambient temperature on the LCD screen.  Here's the program to do so:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">#include &lt;Wire.h&gt;
#include &lt;LiquidCrystal.h&gt;

LiquidCrystal lcd(12, 11, 5, 4, 3, 2); 

#define TEMP_REG 0b00000000
int tmp102 = 0b1001000;  // with ADD0 tied to ground

void setPR(int reg) {
  Wire.beginTransmission(tmp102);
  Wire.send(reg);
  Wire.endTransmission();
}

int getReg() {
  unsigned char lo, hi;

  Wire.requestFrom(tmp102, 2);
  hi = Wire.receive();
  lo = Wire.receive();
  return (hi &lt;&lt; 8) + lo;
}

void setup()   {    
  lcd.begin(16, 2);
  Wire.begin();
  setPR(TEMP_REG);
}

void show_temp() {
  int temp_reg = getReg();
  lcd.setCursor(0, 0);
  show_bin(temp_reg);

  temp_reg &gt;&gt;= 4;

  float temp_C = temp_reg * 0.0625;
  float temp_F = (temp_C * 9 / 5) + 32;

  lcd.setCursor(0, 0);
  lcd.print(temp_C);
  lcd.print("\xdf""C  ");
  lcd.setCursor(0, 1);
  lcd.print(temp_F);
  lcd.print("\xdf""F  ");
}

void loop() {
  show_temp();
}
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The <tt>setup</tt> function sets up the LCD, then uses <tt>setPR</tt> to point the TMP102 at the temperature register.  Subsequent reads will then return the 12-bit encoded temperature.  The <tt>loop</tt> function reads the temperature register, decodes it, and displays the result in both Celsius and Fahrenheit.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Note that this is horrendously inefficient: the TMP102 only measures temperature every 26ms or so, during which <tt>loop</tt>
 will probably run a half-dozen times, feeding the same time strings to 
the LCD each run.  It would be much better to put the TMP102 in one-shot
 mode, and measure the temperature at a much lower frequency - say once a
 second - with a correspondingly low update frequency for the display.  
I'll leave that as an exercise for the reader.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/57-IPv6-Configuration.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">IPv6 Configuration</span></a><div class="lastUpdated">June 27, 2010 5:27 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><a target="_blank" href="http://ipv6.he.net/certification/scoresheet.php?pass_name=djmitche"><img width="229" height="137" border="0" alt="IPv6 Certification Badge for djmitche" src="codevigorous_files/create_badge.png" /></a></div>I've been meaning to get IPv6 set up on my local network for some time.  My only practical reason is that <a href="http://amanda.org/" xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Amanda</a>
 supports IPv6 and I should test that support.  It was also a good 
chance to re-immerse myself in network configuration, and Hurricane 
Electric has a neat <a href="http://ipv6.he.net/certification" xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">certification process</a>
 to add some motivation. I began by getting local IPv6 connectivity set 
up over the HE tunnel, using my Gentoo systems.  This was fairly 
straightforward, as the Gentoo net scripts natively support IPv6.  The 
firewall system I use (<a href="http://www.shorewall.net/" xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Shorewall</a>) does not support IPv6 directly.  Instead, there's a parallel <tt xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">shorewall6</tt>
 package to install.  Aside from the annoyance of setting up two 
separate firewalls, this did not cause appreciable difficulties.  With 
all of this in place, I was at the "Explorer" level.<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
next task was to set up a working IPv6 desktop.  My home network uses 
802.1q VLAN tagging to layer both an external, publicly routable IPv4 
network (99.89.149.16/29 on VLAN 20) and an internal, NAT'd IPv4 network
 (172.16.1/24 on VLAN 10).  I wanted to make VLAN 10 a dual-stack 
network, rather than invent a new VLAN for my IPv6 network.  Initially, I
 didn't realize that HE uses, in my case, 2001:470:1f10:826::0/64 just 
for the tunnel (yes, two addresses out of 2<sup>64</sup> used -- maybe 
we'll need IPv8 sooner than we think!).  I assumed that the /64 I was 
allocated was to be used for all of my nodes, and tried to subnet it 
locally, using 2001:470:1f10:826::0/112 for the tunnel and 
2001:470:1f10::1/112 for the internal network.  This worked with manual 
configuration, but <a href="http://www.litech.org/radvd/">radvd</a> 
seemed to always want to advertise a /64.  A little reading about the RA
 protocol showed this to be correct: RA provides the high 64 bits (the 
network portion), and the clients provide the low 64 bits using EUI-64. 
 I was stymied until I looked at the tunnel details again and noticed 
that the "Routed IPv6 Prefixes" section listed a different prefix 
(2001:470:1f11:826/64).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">With 
this in place, the subnet and firewall setup was a breeze.  Using a 
manual configuration on my MacBook, I was able to communicate via IPv6. 
 However, the stateless autoconfiguration didn't work.  I briefly tried 
DHCPv6, but Macs do not support it.  The RA client correctly combines 
the network and EUI-64 components to create a full address, and it 
correctly copies the link-local address of the router, but it does not 
set up a default route using that router, making the whole thing fairly 
useless.  A trip to #ipv6 confirmed that Macs are, indeed, broken this 
way, so I stopped worrying about it.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
remainder of the certification process involved getting Apache, Postfix,
 and Bind speaking IPv6, none of which was very difficult.  I did 
discover that BIND's $ORIGIN didn't work correctly.  A zonefile with</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">$ORIGIN 6.2.8.0.1.1.f.1.0.7.4.0.1.0.0.2.ip6.arpa.
8.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0 IN PTR knuth.r.igoro.us.
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">didn't
 work, but spelling out the entire reversed address did.  I'm sure this 
was due to a typo, but several checks didn't reveal anything.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">However, I'm now stuck at the Guru level until GoDaddy starts supporting IPv6 glue for the <tt>.us</tt> TLD.  I feel cheated, somehow!</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/59-Whats-New-in-Amanda-The-End-of-Fragmentation.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What's New in Amanda: The End of Fragmentation</span></a><div class="lastUpdated">July 8, 2010 7:07 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Most
 of my posts in this series have been about features that are available 
in a released version of Amanda.  This time, I want to share a project 
I'm working on right now - one that will be available in Amanda-3.2.  
I'm reworking the way Amanda writes its data to tape (or any other kind 
of storage) to make it more efficient, more reliable, and simpler to 
configure.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Historically,
 Amanda's conservative approach to finicky tape hardware has meant that 
it wasted some space at the end of each tape.  With the changes I'm 
working on, Amanda will no longer waste this space, and can also avoid 
some needless copying of data in most cases, with a minimum of 
additional risk. </p><h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Amanda's Storage Format</h1><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Before examining the new functionality, let's look at Amanda's storage format.  Amanda treats all storage devices like tapes<sup>1</sup>
 - a set of sequentially numbered data files of arbitrary size, each 
composed of a sequence of fixed-size blocks.  Each file begins with a 
one-block header that identifies the dump and gives information about 
its contents.  The header is followed by blocks of raw data.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Amanda supports writing a dump across multiple tapes - spanning.<sup>2</sup>
  The technique is this: a dump is split into a sequence of parts, and 
each part is written a a single file on a volume.  During recovery, 
Amanda reads the parts in sequence, and concatenates their data to 
reproduce the original dumpfile.  Usually all parts are the same size, 
and this size is generally 1-5% of the tape capacity.</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Better Safe than Sorry - At a Cost</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Amanda
 was originally designed around tape drives - in fact, if you look at 
the history of Linux kernel support for tape drives, it is closely 
intertwined with Amanda development.  Tape drives are finicky beasts, 
and in many cases cannot distinguish the end of the tape (called EOM) 
from any other fatal error.  Worse, tape drives employ large caches to 
ensure they can write continuously, and when an error occurs all of the 
data in that cache is lost, and there is no way for Amanda to determine 
how much actually made it onto the tape.  Beginning a new on-tape file 
(writing a filemark) flushes the cache and signals any errors 
immediately.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Since
 time immemorial, then, Amanda has treated any error from the tape drive
 as EOM, and assumed that all data written since the last filemark is 
potentially corrupt.  That means that the part in progress when the 
error occurred is logged as PARTIAL, and Amanda will start at the 
beginning of that part on the next tape.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
PARTIAL part is recorded in the catalog, but will not be used for 
recovery, so it is effectively wasted space.  A little arithmetic will 
tell you that, on average, each tape will waste half of the part size.  
This is at least excusable with real tape drives; with vtapes (disk), 
this wasted space is completely unnecessary.  Worse, vtapes are most 
flexible when they are kept small and dumps are spanned over many vtapes
 per night; but the wasted space increases linearly with the number of 
vtapes used.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In 
order to rewind a part and write it again on a new tape, Amanda also 
needs to keep its data somewhere, called the part cache.  When the dump 
is on the holding disk, the holding disk acts as a part cache.  
Otherwise, Amanda can cache parts in memory or on disk.  Caching in 
memory is faster, but requires a lot of RAM for a reasonable part size. 
 Caching on disk allows larger parts, but is considerably slower.</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Logical EOM</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">More 
recent tape drives (those made in the last decade or so) have a feature 
called "early warning".  With this feature enabled, the drive alerts the
 host system when it is "near" EOM, and flushes the cache to tape.  
Exactly what "near" means is not specified in the SCSI standard, but in 
general there's room to flush the cache and write a filemark, at least. 
 This is sometimes called a logical EOM - LEOM.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Amanda
 can take advantage of this functionality to cleanly finish a part 
before running headlong into a physical EOM.  This eliminates the wasted
 space for a PARTIAL part, and also eliminates the need to cache parts, 
since rewinding is not required.  In one small change (well, OK, it's <a href="http://github.com/zmanda/amanda/compare/1bc521c5ce1be2d144fefc8ce37917c55ab690e8...6a087798ea0c9945093226150da37d5af49d1810">about 4,300 lines</a>), Amanda gets faster and uses storage space more efficiently.  What's not to love?</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Better
 yet, all of the non-tape devices (vtapes, S3 devices, DVD-ROMs, etc.) 
can easily emulate LEOM, so backups to these devices will automatically 
benefit from this improvement.</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In the Code</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><a href="http://github.com/zmanda/amanda/compare/1bc521c5ce1be2d144fefc8ce37917c55ab690e8...6a087798ea0c9945093226150da37d5af49d1810">Three important patches</a>
 toward this functionality were just committed.  What remains is to set 
up real LEOM support for the VFS device (vtapes) and for the tape 
device.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
VFS device can, of course, trivially emulate LEOM when it is enforcing 
the MAX_VOLUME_USAGE property - the vtape length.  However, predicting 
when a filesystem will run out of space is much more difficult.  We are 
still discussing options, and I would love to hear suggestions here or 
on the mailing list.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">As 
for the tape device, it will assume that LEOM is not supported unless 
the user configures it explicitly (with the "LEOM" device property) or 
we can determine support for LEOM from the operating system at runtime. 
 Unfortunately, this is one of those areas so technical that only a 
half-dozen people know how it works, so it may take me some time to 
track down this information for non-Linux operating systems.  Again, 
advice and assistance is welcome!</p>

<hr xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" />

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li><sup>1</sup>This is an ages-old design decision, but one that artificially constrains Amanda's flexibility, especially with vtapes.
</li><li><sup>2</sup>In fact, Amanda has supported spanning for 
something like 7 years now.  Yet I occasionally see users in #amanda 
complaining about this serious limitation and wondering when we're going
 to do anything about it.  Will 2003 be soon enough?
</li></ul></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/60-SSH-With-Snow-Leopard.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">SSH With Snow Leopard</span></a><div class="lastUpdated">July 10, 2010 3:27 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I
 just upgraded my Macbook to Snow Leopard, and the upgrade has changed 
the way SSH authentication works.  I have set up a system I like quite a
 bit, now, and thought I would share. My usage pattern is that I do most
 of my work via <a href="http://www.gnu.org/software/screen/">GNU screen</a> running on my login server, <tt>euclid</tt>.  So I want a simple procedure that will connect me to that screen session, with a proper SSH agent set up.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Snow Leopard automatically starts an <tt>ssh-agent</tt> process at login.  This is great, but does not interoperate with <a href="http://sshkeychain.sourceforge.net/">SSHKeychain</a>.
  Dropping SSHKeychain is OK with me - I don't use SSH tunnels, so it 
really only acted as a GUI for passphrase entry.  It also ate CPU 
occasionally, which of course causes the macbook to become more 
painfully hot than usual.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So I 
have three problems to solve: 1. automatically add my key to ssh-agent; 
2. automatically expire the key at appropriate times (at my paranoia 
level, that's at system sleep); and 3. make multiple agent instances 
usable from the same shell session on the server.</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Adding the Key at Connection Time</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Adding the key is relatively straightforward.  I wrote a short script that Terminal runs when I hit -N or -T:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">#! /bin/bash

# does ssh-agent not have a key?
if ! ssh-add -l; then
    ssh-add ~/.ssh/dustin || exit 1
fi

exec ssh -x -t euclid.r.igoro.us bin/startscreen
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
will prompt me for the passphrase when there is not already a key 
active, but proceed directly to the ssh invocation if the key situation 
is OK.  The <tt>-x</tt> option to <tt>ssh</tt> is there to turn off X11 
forwarding; without this option, SSH will helpfully start the X11 app.  I
 think this is a great feature, but I don't use X11 apps very often, so 
I've disabled it.</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Expiring the Key Automatically</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Mac 
OS has a nicely designed system in place to allow applications to get 
notified when the system is changing power states.  However, I wasn't 
interested in writing a full OS X app for this particular project.  
Enter <a href="http://www.bernhard-baehr.de/">sleepwatcher</a>.  This is
 a beautifully simple program that just executes scripts on particular 
power events.  I set this up to run via launchd, as directed in the 
README, and to run <tt>~/.ssh/sleep</tt> on sleep.  That script contains:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">#! /bin/bash

# first, don't inherit a socket (sleepwatcher doesn't get the user's env)
SSH_AUTH_SOCK=

# find some sockets
echo ".ssh/sleep:" `id`
for sock in /tmp/launch-*/Listeners; do
    if [ -w $sock ]; then
        echo "Trying to remove .ssh/dustin from socket $sock"
        SSH_AUTH_SOCK=$sock /opt/local/bin/ssh-add -d ~/.ssh/dustin
    else
        echo "Skipping unwritable socket $sock"
    fi  
done
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The for loop is required because a script run from sleepwatcher doesn't inherit the <tt>SSH_AUTH_SOCK</tt>
 variable that points to the running SSH agent.  The loop simply 
searches for a writable SSH socket of the pattern used by the system's 
agent.</p>

<h1 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">SSH Agent and Screen</h1>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">If 
you navely set up an SSH agent, connect to a remote system, and start 
screen there, things will work great - until you disconnect from the 
screen session.  When you connect to the remote system, SSH forwards the
 agent connection for you, and sets <tt>SSH_AUTH_SOCK</tt> on the remote
 system to point to this forwarded socket.  Screen passes this variable 
along blindly, so it appears in all of the shells opened in screen 
windows, and things work as you'd expect.  When that SSH connection is 
removed, and a new one established, the forwarded agent appears at a new
 socket.  But those shells running in screen windows are still pointing 
to the old name, and will no longer be able to connect.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
fix is to create a socket with a well-known name that will not change 
from connection to connection.  The following script takes care of it.  
WARNING: this script is vulnerable to /tmp race conditions.  I am the 
only user on my servers, so this doesn't bother me, but fixing it should
 be relatively straightforward.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">#! /bin/bash
# hard-link the SSH socket to one with a fixed name on the local
# machine, and set SSH_AUTH_SOCK to point to that fixed name.  Later
# invocations of this script will change the link, but the name will
# remain valid, allowing existing shells to continue to function.
setup_fixed_socket() {
  local old_socket="$SSH_AUTH_SOCK"
  local socket_dir="/tmp/$(uname -n)-$(id -u)"
  local socket_file=$socket_dir/agent

  # set up the directory and permissions
  [ -e $socket_dir ] || mkdir -p $socket_dir
  chmod 700 $socket_dir

  # remove an existing link
  [ -e $socket_file ] &amp;&amp; rm $socket_file

  # hard-link in the new one
  ln $old_socket $socket_file

  # return the new socket
  echo $socket_file
}

# this variable will be exported to every shell opened by this
# invocation of screen -- even subsequent connections to it.  This
# variable may live for days or weeks.
export SSH_AUTH_SOCK=$(setup_fixed_socket)

# finally, fire up screen.  Try reattaching to a running
# session; otherwise start up a new one
screen -R -DD ${@} || screen
</pre></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/61-IPv6-and-Amanda.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">IPv6 and Amanda</span></a><div class="lastUpdated">July 16, 2010 11:04 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Amanda
 joined the IPv6 revolution in November 2006 - all of the BSD-style 
authentication mechanisms can support IPv6 endpoints.  However, it's 
generally agreed that this was a mistake, and in this post I will talk 
about why that's the case. First, a bit of background on how Amanda's 
networking code works, and what had to change to support IPv6.  Amanda 
supports security mechanisms called BSD (the oldest), BSDUDP, and 
BSDTCP.  These all authenticate (if you can call it that) using the same
 sorts of checks that rsh uses.  The incoming connection is accepted if:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>it is from a "reserved" port (less than 1024);
</li><li>the address of the initiator has complementary forward and reverse DNS records in place; and</li>
<li>the initiator's hostname is in <tt>.amandahosts</tt></li>
</ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">During a backup operation, the Amanda server contacts each client host.  When using the BSD authentications, this triggers <tt>amandad</tt>,
 which checks the above restrictions before beginning communication with
 the server.  This initial connection is packet-based, and can be 
carried out over UDP (for BSD and BSDUDP) or TCP (BSDTCP).  When a dump 
begins, several "streams" are opened to transmit the data, index, and 
metadata.  For BSD and BSDUDP, each stream is implemented as a distinct 
TCP connection, where the client sends a port number to the server and 
the server connects to that port.  BSDTCP multiplexes all streams over a
 single TCP connection using a basic type/length packet encapsulation.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
first challenge in adding IPv6 support was to deal properly with IPv6 
addresses when querying the DNS.  That meant switching to getaddrinfo 
and getnameinfo, as suggested by <a href="http://www.kame.net/newsletter/19980604/">Jun-ichiro itojun Itoh</a>. These functions bring their own compatibility problems, but Amanda uses <a href="http://www.gnu.org/software/gnulib/">gnulib</a>, which provides compatibile implementations on systems where they are not available, minimizing the difficulty.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">We 
had a lot of trouble from systems such as RHEL3 possessing IPv6 support 
in the compiler environment but not in the kernel.  On such systems, 
code using constants like AF_INET6 or AI_V4MAPPED would compile without 
problems, but fail at runtime.  We added a WORKING_IPV6 preprocessor 
conditional, without which all references to IPv6-related symbols were 
removed.  At configure time, Amanda tries to create an IPv6 socket, and 
sets this conditional to true if it succeeds.  The <tt>--without-ipv6</tt> configure option forcibly disables IPv6 support.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
sockaddr structures and API for IPv6 are fairly difficult to use, 
particularly if it's not known in advance what sort of address they will
 contain.  We added a set of macros and utility functions in <a href="http://github.com/zmanda/amanda/blob/master/common-src/sockaddr-util.c">sockaddr-util.c</a> and <a href="http://github.com/zmanda/amanda/blob/master/common-src/sockaddr-util.h">sockaddr-util.h</a>.
  Using these macros throughout Amanda removed a significant amount of 
code that was conditionalized on both compile-time support and runtime 
address family, and centralized that logic in one easily-maintained 
place.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">On 
our build systems, we had to deal with different levels of support in 
the compile environment and the kernel.  This is fine: most Amanda users
 install binary packages that are produced on roughly the same OS 
distribution and version as was used for the build, so the kernel 
support is generally the same.  However, a third variable has tripped up
 lots of Amanda users: system configuration.  In particular, several 
newer Linux distributions have shipped with <tt>localhost</tt> resolving to ::1 vi <tt>/etc/hosts</tt>,
 but without enough interface configuration to actually utilize a socket
 bound to that address.  Amanda uses localhost sockets for inter-process
 communication, so this misconfiguration causes backup operations to 
fail.  The solution is to either finish configuring IPv6 on the host, 
remove the reference to ::1 in <tt>/etc/hosts</tt>, or build Amanda with <tt>--without-ipv6</tt>.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
have not yet heard of an Amanda installation where IPv6 communication is
 in use.  But I have heard from countless IPv4 users whose Amanda 
installations have failed due to bad IPv6 support.  At the moment, then,
 I feel that adding IPv6 support to Amanda has been a net negative for 
the project.  Although there is doubtless room for improvement, I will 
not entertain patches for better IPv6 support, for fear they will 
introduce new bugs for our exclusively IPv4 userbase.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Of course, all of this may change as dual-stack networks grow more prevalent and are replaced by pure IPv6 networks!</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/63-irssi-settings-for-status-in-nick.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">irssi settings for status-in-nick</span></a><div class="lastUpdated">October 22, 2010 1:06 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I
 am getting started in releng at Mozilla, and IRC provides a central 
meeting-place for the group.  As such, indicating your status to this 
group is an important, so others can know whether you're nearby to 
answer a question or take care of a problem.  This is generally done by 
adding suffixes to the IRC nickname, e.g., "dustin|afk" or 
"dustin|lunch".</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Before
 I go further, I know that this is frown on, and even results in 
autoignores, in some corners of IRC.  If that's the case for you, read 
no further. <a href="http://irssi.org/">Irssi</a>'s documentation is 
utterly incomplete.  So the only way to figure out how to configure 
something or write a script is to find and adapt examples.  So hopefully
 this entry will feed back into that pool.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What I want is an easy way to bind some keystrokes to commands like <tt>/NICK dustin|afk</tt>.  However, I want to be very careful <i>not</i>
 to set this nick on other chatnets, particularly since I'm generally 
known as djmitche there, not dustin.  So I began by writing a script 
that can double-check this:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">use strict;

use vars qw ($VERSION %IRSSI);

$VERSION = 'v1.0';
%IRSSI = (
          name        =&gt; 'moznick',
          authors     =&gt; 'dustin',
          contact     =&gt; 'dustin@mozilla.com',
          url         =&gt; 'http://code.v.igoro.us/',
          license     =&gt; 'GPLv2',
          description =&gt; 'Sets my nick status for Mozilla co-workers',
         );

use Irssi;

my $last_nick = '';

sub is_mozilla {
    my ($server) = @_;
    if (!$server || $server-&gt;{'chatnet'} eq 'mozilla') {
        return 1;
    }

    Irssi::print("This isn't a mozilla channel!");
    return 0;
}

sub cmd_moznick {
    my ($data, $server, $channel) = @_;

    if (is_mozilla($server)) {
        my $new_nick = $data? "dustin|$data" : "dustin";
        return if ($new_nick eq $last_nick);

        $server-&gt;command("NICK $new_nick");
        Irssi::print("nick set to $new_nick");
        $last_nick = $new_nick;
    }
}

Irssi::command_bind("moznick", "cmd_moznick");
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This just adds a <tt>/MOZNICK</tt>
 command that will set my nick, but only on a Mozilla chatnet.  Then I 
added an alias and some bindings.  I don't like irssi's 
configuration-writing stuff, as it's several times blown away my 
configuration.  Instead, I edit the config file directly.  So I have:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">aliases = { 
    moznick_moz = "window goto #build; moznick $*";
};

keyboard = ( 
    { key = "meta-space"; id = "multi"; data = "command moznick_build"; },
    { key = "meta-z"; id = "multi"; data = "command moznick_build brb"; },
    { key = "meta-x"; id = "multi"; data = "command moznick_build away; command away"; }
);
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The advantage of the <tt>window goto</tt>
 in the alias is that it will switch to a channel on the mozilla 
chatnet.  I'd love to have a way to just switch to that chatnet without 
changing windows, but this isn't bad.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/65-Firefox-4.0b7-a-few-tweaks.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Firefox 4.0b7 - a few tweaks</span></a><div class="lastUpdated">November 10, 2010 4:44 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The
 new beta of Firefox 4.0 was released today.  I'm not quite willing to 
run Minefield (nightlies), so I've been eagerly awaiting this beta to 
fix some nagging but not show-stopper bugs in 4.0b6.  One of those 
involved bad interactions of App Tabs with Panorama.  Now the app tabs 
nicely decorate the side of each tab set in the panorama view.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Another
 nice thing is that the Option-Space key combination, which opened 
panorama in 4.0b6, no longer does so.  That's OK - I found that to be 
too easy to press anyway.  It's now bound to Command-E (right there at 
the top of the "View" menu).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Panorama
 has also been re-bound to swipe-up and swipe-down, which makes me less 
happy.  In most apps on the Mac, those swipes are equivalent to the 
"Home" and "End" keystrokes -- they scroll to the top or bottom of the 
current page.  So with a little help from my new co-workers, I 
discovered the settings to fix that.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The full list of gesture bindings is <a href="http://t.tal.by/post/95428783/changing-firefox-gestures">written up here</a>, but the two I needed to change are <tt>browser.gesture.swipe.up</tt> and <tt>.down</tt>.  The scrolling commands to bind to them are <tt>cmd_scrollTop</tt> and <tt>cmd_scrollBottom</tt>.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">4.0 has a number of other great UI enhancements, too.  I'm excited to see 4.0 finally released!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">[edit: fixed formatting] </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/66-virtualenv-for-Perl.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">virtualenv for Perl</span></a><div class="lastUpdated">November 11, 2010 11:48 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I absolutely love <a href="http://pypi.python.org/pypi/virtualenv">virtualenv</a> for Python development.  It allows me to develop <a href="http://buildbot.net/">Buildbot</a>
 against several versions of Python and several versions of its 
dependencies, without modifying my system's Python installation at all!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Now, I need to do the same thing in Perl.  So I thought I'd compare the two side-by-side.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p><h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">virtualenv</h2><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"></p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"># install virtualenv locally
wget http://bitbucket.org/ianb/virtualenv/raw/tip/virtualenv.py
# set up a sandbox
python virtualenv.py sandbox
# activate it
source sandbox/bin/activate
# start installing stuff
easy_install buildbot
</pre>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">local::lib</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">There is no local::lib gentoo ebuild!  I'm sure there's a good reason, but that's odd all the same!</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"># install local::lib locally
wget http://search.cpan.org/CPAN/authors/id/G/GE/GETTY/local-lib-1.006007.tar.gz
tar -zxf local-lib-1.006007.tar.gz
cd local-lib-1.006007
perl Makefile.PL --bootstrap # (accept lots of defaults)
make test &amp;&amp; make install
# activate it (permanently)
echo 'eval $(perl -I$HOME/perl5/lib/perl5 -Mlocal::lib)' &gt;&gt;~/.bashrc
eval $(perl -I$HOME/perl5/lib/perl5 -Mlocal::lib)
# start installing stuff
perl -MCPAN -e install Config::General # (I have to accept the same defaults again??)
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I think virtualenv is the clear winner here!</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/67-Subscribe-to-a-google-group-with-a-different-address.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Subscribe to a google group with a different address?</span></a><div class="lastUpdated">September 2, 2011 4:04 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Google
 Groups is one place where, IMHO, Google pushes its hegemony too far, 
making it difficult to use.  I wanted to subscribe to puppet-users with 
my Mozilla address, but since I have a Google account, Groups assumes I 
want to subscribe with that address.  No!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I found the fix with a bit of Googling (some irony there).  It involves editing a URL:</p>

<blockquote xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">http://groups.google.com/group/puppet-users/boxsubscribe?email=email@domain.com</blockquote>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">where you'd substitute the name of the group you want for <i>puppet-users</i> and add your email at the end. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/68-Amandas-Transfer-Mechanisms.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Amanda's Transfer Mechanisms</span></a><div class="lastUpdated">January 22, 2011 3:47 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">There's
 been a bit of confusion on the mailing list and IRC about how Amanda 
assembles transfers out of transfer elements, and how transfer 
mechanisms influence that.  </p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In the final form of a transfer, any two adjacent elements must have
the <em>same</em> mechanism.  For example is, an upstream element speaking
XFER_MECH_PUSH_BUFFER cannot talk to a downstream element using
XFER_MECH_READ_FD (nor, more confusingly, XFER_MECH_PULL_BUFFER).  So each mechanism is an
isolated definition of "here's how upstream and downstream should
talk".  They come in pairs because generally anything upstream can do
to downstream (e.g., upstream can write to downstream's fd) can occur
in reverse (e.g., downstream can read from upstream's fd).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">What 
makes this confusing is that if you specify a set of elements which 
can't talk directly to one another, then xfer.c will add "glue" elements
 <em>between</em> the specified elements.  To make that concrete, imagine you specify a transfer as</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">source-holding --&gt; filter-xor --&gt; dest-fd</pre>

(if you like practical examples, then imagine filter-xor is a 
buffer-based decompression filter, and you're pulling data from holding 
disk, decompressing, and sending to a pipe -- something amfetchdump 
would do).  Here are the mechanisms supported by each element:

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">source-holding:
 XFER_MECH_PULL_BUFFER
</pre>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">filter-xor
 XFER_MECH_PULL_BUFFER (input) and
 XFER_MECH_PULL_BUFFER (output)
or
 XFER_MECH_PUSH_BUFFER (input) and
 XFER_MECH_PUSH_BUFFER (output)
</pre>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">dest-fd
 XFER_MECH_WRITEFD (input)
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In 
putting these together, source-holding and filter-xor can use the same 
mechanism (PULL_BUFFER).  This leaves filter-xor using PULL_BUFFER for 
output, but dest-fd does not support this.  So xfer.c adds a glue 
element that can speak PULL_BUFFER on input and WRITEFD on output.  This
 element basically loops in a thread, calling upstream-&gt;pull_buffer 
and write(downstream-&gt;input_fd, buffer).  So the final xfer looks 
like</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"> source-holding --(PULL_BUFFER)--&gt; filter-xor --(PULL_BUFFER)--&gt; glue --(WRITEFD)--&gt; dest-fd
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Hopefully that helps to explain how the glue works.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Note 
that one of the cool things about this arrangement is that in most cases
 the complexity is in the glue, not the elements.  In fact, in this case
 the glue provides the only thread that's required to run this transfer,
 so the other three element implementations don't need to manage threads
 at all. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/69-Nagios-NSCA-from-Python.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Nagios NSCA from Python</span></a><div class="lastUpdated">May 20, 2011 5:55 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I've
 been working on improving the monitoring of the build slaves at 
Mozilla.  As part of this project, I needed to be able to submit passive
 check results to the Nagios servers via <a href="http://community.nagios.org/2009/06/11/nagios-setting-up-the-nsca-addon-for-passive-checks/">NSCA</a>
 during system startup.  I'm doing this from a Python script that needs 
to run on a wide array of systems using whatever random Python is 
available.  We run some oddball stuff, so the common denominator is 
Python 2.4.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">It turns out that there's no Python NSCA library, although there is <a href="http://search.cpan.org/dist/Net-Nsca/lib/Net/Nsca.pm">Net::Nsca</a> in Perl.  So, I wrote one, and put it on github: <a href="https://github.com/djmitche/pynsca">https://github.com/djmitche/pynsca</a>.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">At 
the moment, this only knows XOR, and only does service checks.  That's 
all I need, but hopefully it can be easily expanded to cover other 
purposes.  The one thing I want to avoid is adding mandatory 
requirements -- this should work, at least in plain-text and XOR modes, 
on a plain-vanilla Python installation.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">By the way, the startup script I'm working on is <a href="http://hg.mozilla.org/build/puppet-manifests/file/tip/modules/buildslave/files/runslave.py">runslave.py</a>, which includes a modified copy of <i>pynsca</i> and does a number of other housekeeping jobs as well.  More on that in a subsequent post. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/70-IT-and-Community.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">IT and Community</span></a><div class="lastUpdated">November 17, 2011 12:05 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Mozilla's IT team is pivoting to a more community-focused approach.  Our director of IT, mrz, has been <a href="http://blog.mozilla.com/mrz/2011/10/06/my-job-after-5-558-years/">writing</a> <a href="http://blog.mozilla.com/mrz/2011/10/12/step-1-community-it/">extensively</a> <a href="http://blog.mozilla.com/mrz/2011/10/28/step-1-01-mozilla-it-mozcamp/">about</a> <a href="http://htmlpad.org/community-IT-slides/#">it</a> over the last few weeks.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">As 
you can imagine, the difficult part of this is to balance security with 
accessibility.  We'd like to be open, but we can't give the keys to the 
kingdom out to anyone who promises to help.  The approach we're taking 
is to treat volunteers as we would part-time employees - post positions,
 interview, and then supervise to gain trust.  This is a fairly common 
model, actually, for any organization with volunteers and a need for 
security.  Youth programs, for example, generally do an interview and 
background check with new volunteers, and those volunteers will be 
paired with senior volunteers or staff for a while.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">However,
 it's a bit cumbersome, both for Mozilla and for potential volunteers.  
We must design entire positions - ongoing tasks or roles that a 
volunteer can work on for an extended period of time - and then select a
 limited number of volunteers to fill those roles.  For potential 
volunteers, an application and interview can mean a long time (weeks?) 
before they get to do anything hands-on.  It also carries the risk that 
we'd have to turn a qualified volunteer away due to lack of suitable 
positions.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><b>So what to do?</b></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">We 
need a more fluid way of interacting with potential contributors.  Since
 our bug database is public, we can begin by simply tagging a few bugs 
that are appropriate for newcomers -- things that don't require 
sensitive access and are well-encapsulated so they can be completed 
without extensive knowledge of Mozilla's infrastructure.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><a href="http://bit.ly/tTsnix">Here's the list.</a></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">It's a bit short right now.  There are a few things that may help:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>We can get better about identifying appropriate tasks and projects and making bugs out of them.
</li><li>We can identify a means of giving limited or sandboxed access to a new volunteer.
</li><li>Consumers of Mozilla's IT resources can begin tagging bugs, 
where Mozilla can provide the resources and volunteers can do the heavy 
lifting - got any ideas?
</li></ul></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/71-Setting-up-a-buildslave-instance-remotely-on-OS-X-Lion.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Setting up a buildslave instance remotely on OS X Lion</span></a><div class="lastUpdated">March 17, 2012 7:05 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Byrce Lelbach has generously offered access to an OS X system as a <a href="http://buildbot.net/metabuildbot">metabuildbot</a>
 slave.  As I went about setting it up today, the process was not 
obvious, so I thought I'd share.  This was interesting mostly because I 
only have SSH access to the host, so I cannot download things from the 
Apple Store or do any of the fancy point-and-click stuff that would make
 this easier.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">First,
 I needed to get XCode installed.  Note that the (much quicker to 
download) XCode command-line tools are not sufficient to build 
everything in MacPorts -- in particular, they do not support building 
zlib, which is required for git-core.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I got my hands on a copy of "Install XCode.app", and:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">host:Downloads buildbot$ cd Install\ Xcode.app/Contents/
host:Contents buildbot$ sudo installer -package Resources/Xcode.mpkg -target /
Password:
installer: Package name is Xcode
installer: Upgrading at base path /
installer: The upgrade was successful.
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Once this was done, I installed MacPorts:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">host:Downloads buildbot$ hdiutil mount MacPorts-2.0.4-10.7-Lion.dmg
Checksumming Driver Descriptor Map (DDM : 0)
     Driver Descriptor Map (DDM : 0): verified   CRC32 $A913D2D8
Checksumming Apple (Apple_partition_map : 1)
....
     Apple (Apple_partition_map : 1): verified   CRC32 $A1DF5DC1
Checksumming disk image (Apple_HFS : 2)
...... (...) .....
          disk image (Apple_HFS : 2): verified   CRC32 $5A3E74A0
Checksumming  (Apple_Free : 3)
                    (Apple_Free : 3): verified   CRC32 $00000000
verified   CRC32 $D9641854
/dev/disk2              Apple_partition_scheme
/dev/disk2s1            Apple_partition_map
/dev/disk2s2            Apple_HFS                       /Volumes/MacPorts-2.0.4
host:Downloads buildbot$ pushd /Volumes/MacPorts-2.0.4/
/Volumes/MacPorts-2.0.4 ~/Downloads
host:MacPorts-2.0.4 buildbot$ sudo installer -package MacPorts-2.0.4.pkg/ -target /
Password:
installer: Package name is MacPorts-2.0.4
installer: Installing at base path /
installer: The install was successful.
host:MacPorts-2.0.4 buildbot$ popd
host:Downloads buildbot$ hdiutil unmount /Volumes/MacPorts-2.0.4
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">and we're off to the races.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I added <tt>/opt/local/bin</tt> to my path as suggested, and then followed the normal MacPorts setup process.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Finishing up the buildslave install required installing Git (which manages to pull in unreasonable amounts of other stuff!)</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">host:Contents buildbot$ sudo  /opt/local/bin/port install git-core -credential_osxkeychain-doc-pcre-python27
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">which is required for the source steps, then creating a virtualenv to install buildbot-slave:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">host:~ buildbot$ virtualenv sandbox
New python executable in sandbox/bin/python
Installing setuptools............done.
Installing pip...............done.
host:~ buildbot$ source sandbox/bin/activate
(sandbox)host:~ buildbot$ pip install buildbot-slave
...
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">and then create and start a slave:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">(sandbox)host:~ buildbot$ buildslave create-slave buildslave buildbot.buildbot.net:9989 HOSTNAME PASS
...
(sandbox)host:~ buildbot$ buildslave start buildslave
...
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I then followed the helpful advice <a href="http://kb.askmonty.org/en/buildbot-setup-buildbot-setup-for-macosx">here</a> to set up a plist that will start the daemon on boot. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/72-TIL-about-SSL-certificate-chains.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">TIL about SSL certificate chains</span></a><div class="lastUpdated">May 9, 2012 4:43 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I'm
 laying some SSL groundwork for a project to allow puppet clients to 
move between puppet servers without requiring a central CA, and without 
requiring each client to be aware of all masters.  More on that in a 
future post.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Based on <a href="http://projects.puppetlabs.com/projects/puppet/wiki/Multiple_Certificate_Authorities">"Multiple Certificate Authorities"</a>, I would like to have certificate chains that look like this:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">      +-puppetmaster1 CA--+-puppetmaster1 server cert
      |                   |
      |                   +-client 1 server cert
root--+                   :
      |                   
      +-puppetmaster2 CA--+-puppetmaster2 server cert
                          |
                          +-client 10 server cert
                          :
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Then 
all of the certificate validation would be done with the root CA 
certificate as the trusted certificate.  A server certificate signed by 
puppetmaster2's CA cert should then validate on puppetmaster1.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Building the certificates wasn't all that difficult - see <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=733110#c8">my comment on the bug</a>
 for the script.  However, while making sure the verification worked, I 
ran into some non-obvious limitations of OpenSSL that are worth writing 
down.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I began by running "openssl verify":</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">[root@relabs-puptest1 ~]# openssl verify -verbose -CAfile puptest-certs/root-ca.crt -purpose sslclient puptest-certs/relabs08.build.mtv1.mozilla.com.crt 
puptest-certs/relabs08.build.mtv1.mozilla.com.crt: CN = relabs08.build.mtv1.mozilla.com, emailAddress = release@mozilla.com, O = "Mozilla, Inc.", OU = Release Engineering
error 20 at 0 depth lookup:unable to get local issuer certificate
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">the 
problem here is that the intermediate certificate is not available to 
the verification tool.  Sources suggest to include it with the server 
cert, by concatention, with the server cert last:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">cat puptest-certs/relabs-puptest1.build.mtv1.mozilla.com-ca.crt puptest-certs/relabs08.build.mtv1.mozilla.com.crt &gt; relabs08-with-intermed.crt
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">However,
 after some struggle I learned that "openssl verify" does not recognize 
this format -- it will only look at the first certificate in the file 
(the intermediate), and if you don't look carefully you'll find that it 
successfully verifies the intermediate, not the server certificate!  
Sadly, s<em>client and s</em>sever don't support it either.  Apache httpd supports it with <a href="http://httpd.apache.org/docs/2.2/mod/mod_ssl.html#sslcacertificatepath">SSLCACertificatePath</a>.
  This will feed the certificate chain to the client, and also allow 
httpd to verify client certificates without requiring the clients to 
support an intermediate.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The Apache config is</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Listen 1443

&lt;VirtualHost *:1443&gt;
        ServerName relabs-puptest1.build.mtv1.mozilla.com
        SSLEngine on
        SSLProtocol -ALL +SSLv3 +TLSv1
        SSLCipherSuite ALL:!ADH:RC4+RSA:+HIGH:+MEDIUM:-LOW:-SSLv2:-EXP

        SSLCertificateFile /etc/httpd/relabs-puptest1.build.mtv1.mozilla.com.crt
        SSLCertificateKeyFile /etc/httpd/relabs-puptest1.build.mtv1.mozilla.com.key
        SSLCACertificatePath /etc/httpd/ca-path

        # If Apache complains about invalid signatures on the CRL, you can try disabling
        # CRL checking by commenting the next line, but this is not recommended.
        #SSLCARevocationFile     /etc/puppet/ssl/ca/ca_crl.pem
        SSLVerifyClient require
        SSLVerifyDepth  2

&lt;/VirtualHost&gt;
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">While
 you're getting that set up, you're probably wondering where to get this
 fancy "c_rehash" utility.  Don't bother.  It's about as simple as:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">for i in *.crt; do
        h=`openssl x509 -hash -noout -in $i`
        rm -f $h.0
        ln -s $i $h.0
done
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">As a side-note, the results of verification by s<em>client and s</em>server
 are not very obvious.  Look for the overall error message near the 
bottom of the output.  Here's the result of a client verification once I
 had everything put together, with some long uselessness elided:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">[root@relabs-puptest1 ~]# openssl s_client -verify 2 -CAfile puptest-certs/root-ca.crt -cert puptest-certs/relabs08.build.mtv1.mozilla.com.crt -key puptest-certs/relabs08.build.mtv1.mozilla.com.key -pass pass:clientpass -connect localhost:1443
verify depth is 2
CONNECTED(00000003)
depth=2 CN = PuppetAgain Root CA, emailAddress = release@mozilla.com, OU = Release Engineering, O = "Mozilla, Inc."
verify return:1
depth=1 CN = CA on relabs-puptest1.build.mtv1.mozilla.com, emailAddress = release@mozilla.com, O = "Mozilla, Inc.", OU = Release Engineering
verify return:1
depth=0 CN = relabs-puptest1.build.mtv1.mozilla.com, emailAddress = release@mozilla.com, O = "Mozilla, Inc.", OU = Release Engineering
verify return:1
---
Certificate chain
 0 s:/CN=relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
   i:/CN=CA on relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
 1 s:/CN=CA on relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
   i:/CN=PuppetAgain Root CA/emailAddress=release@mozilla.com/OU=Release Engineering/O=Mozilla, Inc.
 2 s:/CN=PuppetAgain Root CA/emailAddress=release@mozilla.com/OU=Release Engineering/O=Mozilla, Inc.
   i:/CN=PuppetAgain Root CA/emailAddress=release@mozilla.com/OU=Release Engineering/O=Mozilla, Inc.
---
Server certificate
-----BEGIN CERTIFICATE-----
MIIEeTCCA2GgAwIBAgIBATANBgkqhkiG9w0BAQUFADCBkTE1MDMGA1UEAxMsQ0Eg
...
H90rZMVxsVyPHjjfXkeeFcSWyUnV/z3G9osrI9I9SaQ1o9bDc7ZheyHbWbhn
-----END CERTIFICATE-----
subject=/CN=relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
issuer=/CN=CA on relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
---
Acceptable client certificate CA names
/CN=PuppetAgain Root CA/emailAddress=release@mozilla.com/OU=Release Engineering/O=Mozilla, Inc.
/CN=CA on relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
/CN=CA on relabs-puptest2.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
---
SSL handshake has read 5379 bytes and written 1716 bytes
---
---
New, TLSv1/SSLv3, Cipher is DHE-RSA-AES256-SHA
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: zlib compression
Expansion: zlib compression
SSL-Session:
    Protocol  : TLSv1
    Cipher    : DHE-RSA-AES256-SHA
    Session-ID: E30634D9CFCC2FA327282DA813BB550C24ACDF18194E5F13C4981AA55914B5F0
    Session-ID-ctx: 
    Master-Key: 013EB09B066418694D36D74B414BBA42E52DBF0066314B60FC7A74662A60934282B6C37C5C82026F70287E60F4FF9472
    Key-Arg   : None
    Krb5 Principal: None
    PSK identity: None
    PSK identity hint: None
    TLS session ticket:
    0000 - 82 5f 17 72 97 bd f3 1e-ec 24 de 69 ab 1e cd 1d   ._.r.....$.i....
    ....
    0520 - 40 05 b3 27 20 00 8d ce-93 a9 48 81 8f 0c 16 5b   @..' .....H....[

    Compression: 1 (zlib compression)
    Start Time: 1336582165
    Timeout   : 300 (sec)
    Verify return code: 0 (ok)
---
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">note the "Verify return code" at the bottom. </p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">By way of demonstration that the server is actually checking those certs:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">[root@relabs-puptest1 ~]# openssl s_client -verify 2 -CAfile puptest-certs/root-ca.crt -cert bogus.crt -key bogus.key -pass pass:boguspass -connect localhost:1443
verify depth is 2
CONNECTED(00000003)
depth=2 CN = PuppetAgain Root CA, emailAddress = release@mozilla.com, OU = Release Engineering, O = "Mozilla, Inc."
verify return:1
depth=1 CN = CA on relabs-puptest1.build.mtv1.mozilla.com, emailAddress = release@mozilla.com, O = "Mozilla, Inc.", OU = Release Engineering
verify return:1
depth=0 CN = relabs-puptest1.build.mtv1.mozilla.com, emailAddress = release@mozilla.com, O = "Mozilla, Inc.", OU = Release Engineering
verify return:1
140283463366472:error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca:s3_pkt.c:1193:SSL alert number 48
140283463366472:error:140790E5:SSL routines:SSL23_WRITE:ssl handshake failure:s23_lib.c:184:
---
Certificate chain
 0 s:/CN=relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
   i:/CN=CA on relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
 1 s:/CN=CA on relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
   i:/CN=PuppetAgain Root CA/emailAddress=release@mozilla.com/OU=Release Engineering/O=Mozilla, Inc.
 2 s:/CN=PuppetAgain Root CA/emailAddress=release@mozilla.com/OU=Release Engineering/O=Mozilla, Inc.
   i:/CN=PuppetAgain Root CA/emailAddress=release@mozilla.com/OU=Release Engineering/O=Mozilla, Inc.
---
Server certificate
-----BEGIN CERTIFICATE-----
MIIEeTCCA2GgAwIBAgIBATANBgkqhkiG9w0BAQUFADCBkTE1MDMGA1UEAxMsQ0Eg
...
H90rZMVxsVyPHjjfXkeeFcSWyUnV/z3G9osrI9I9SaQ1o9bDc7ZheyHbWbhn
-----END CERTIFICATE-----
subject=/CN=relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
issuer=/CN=CA on relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
---
Acceptable client certificate CA names
/CN=PuppetAgain Root CA/emailAddress=release@mozilla.com/OU=Release Engineering/O=Mozilla, Inc.
/CN=CA on relabs-puptest1.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
/CN=CA on relabs-puptest2.build.mtv1.mozilla.com/emailAddress=release@mozilla.com/O=Mozilla, Inc./OU=Release Engineering
---
SSL handshake has read 3984 bytes and written 997 bytes
---
New, TLSv1/SSLv3, Cipher is DHE-RSA-AES256-SHA
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: zlib compression
Expansion: NONE
SSL-Session:
    Protocol  : TLSv1
    Cipher    : DHE-RSA-AES256-SHA
    Session-ID: 
    Session-ID-ctx: 
    Master-Key: 07E536F1C69A856857EA95DFD821BD6BBD499B5710642F9396D9525637EAD17C03064D5115B3D7F517EDE189E7AF40F8
    Key-Arg   : None
    Krb5 Principal: None
    PSK identity: None
    PSK identity hint: None
    Compression: 1 (zlib compression)
    Start Time: 1336582289    Timeout   : 300 (sec)
    Verify return code: 0 (ok)
---
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Note the handshake failures near the top, where httpd closed the connection on the client.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The next step is to make CRLs work properly, since Puppet uses them extensively. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/73-Trapped-in-Google.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Trapped in Google?</span></a><div class="lastUpdated">May 19, 2012 7:33 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Whenever
 I search in Aurora on my phone, I'm taken to a stripped-down version of
 the page with the header "this page adapted for your browser".</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">How 
do I fix this?  I'd rather fix it with a Google preference, but barring 
that I expect that Firefox has a way for me to regain control of my 
online experience? </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/74-Wireless-Data-in-Belgium.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Wireless Data in Belgium</span></a><div class="lastUpdated">June 7, 2012 8:56 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In hopes this will be useful to others:</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
have an unlocked AT&amp;T phone (Samsung Galaxy Nexus), and needed a 
data plan in Belgium (Brussels, specifically).  I really don't intend to
 text or talk, but data is important.  Most of the news kiosks are happy
 to sell you a SIM, but with no data portion.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">A 
fellow Mozillian, Ben Kero, recommended BASE wireless.  There was a spot
 in the airport, but they were out of SIMs.  I borrowed some wifi, 
looked up another location on <a href="http://www.base.be/">base.be</a>, and went there.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">They 
have a 1-GB plan for 15, called "surf &amp; mail 15".  What you'll get 
is a 15 SIM card with 15 credit on it, and a brochure giving 
instructions to send a text message to activate the 15 plan using that 
credit.  When I did so, I immediately received a text indicating I did 
not have sufficient credit, but the data seems to work.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Which is good, because the wifi in the apartment we're staying at is pretty poor. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/75-Mobile-data-while-travelling-in-Great-Britain.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Mobile data while travelling in Great Britain</span></a><div class="lastUpdated">June 12, 2012 7:29 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Three
 wireless was recommended for my trip here, but they were out of SIMs 
(which seems a common malady), so I dropped by the T-Mobile store.  They
 set me up with a 5 SIM with unlimited data for 30 days, which seemed 
great.  But read on.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">As I 
walked out the door of the shop, I went to look up bars in Edinburgh, 
and was presented with a "prove you're 18 with a credit card" form, 
courtesy T-Mobile.  Of course, I don't have a UK credit card, so I 
turned around and walked back into the shop.  They fixed this up without
 any additional trouble -- but there would have been more trouble had I 
not immediately looked for something not "child-safe" (Which brings up 
the recurring question: what on earth have legislators been smoking to 
think that children should not be able to visit breweries' and bars' 
websites?  Do they think that the "series of tubes" can, in the hands of
 n'er-do-wells, carry grain alcohol straight to the mouths of babes?).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I subsequently noticed that they block IRC - not such a big deal, since they do not block SSH, which is how I usually use IRC.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">And 
now that I'm on my laptop and not my mobile, I notice that they are also
 injecting their JavaScript into every (non-SSL) page I visit, helpfully
 shrinking images and adding keyboard shortcuts to un-shrink them.  And 
probably capturing passwords, too.  Lovely.  I'm sure they're doing so 
to "protect" me.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">For 
the moment, I'm really only using the data to figure out where to go 
next, and what to drink when I get there, and only for a few days.  Even
 so, this intrusion into my privacy galls me.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Steer clear of T-Mobile, if you value your online life.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/76-Building-a-partitioned-log-table.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Building a partitioned log table</span></a><div class="lastUpdated">September 13, 2012 10:46 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">For
 a project at Mozilla that involves re-imaging hundreds of mobile 
devices, we want to gather logs in a database for failure analysis.  
Mobile devices fail all the time -- not sure if you knew that.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">We'll
 probably end up with 1,000-10,000 log entries per day.  We'd like to 
expire them on a relatively aggressive schedule -- no need for 
historical analysis at this level.  So that means not only a lot of 
inserts, but a lot of deletes.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">We're
 using MySQL as the database backend, and MySQL doesn't do well with 
deletes - it just marks the row as deleted, but doesn't reclaim the 
space, and in fact doesn't even remove the row from consideration in 
queries.  So if you blindly insert and delete in a table, MySQL will eat
 disk space and get progressively slower.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">One 
fix to this is to optimize the table periodically.  However, this 
requires a full lock of the table for the duration of the optimize, 
which can be quite a while.  We dont' want to cause a backup of 
production tasks while this is going on.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
other option is to partition the table.  A partitioned table is 
basically a set of tables (partitions) with the same columns, organized 
to look like a single table.  There's a partitioning function that 
determines in which partition a particular row belongs.  There are a few
 advantages.  Each partition is a fraction of the size of the whole 
table, so inserts are quicker (once the appropriate table is 
determined).  The query engine can use "partition pruning" to ignore 
partitions that could not hold rows relevant to the query.  Finally, 
dropping an entire partition at once is a very simple operation, and 
doesn't leave any garbage  that needs to be optimized away.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">For 
logs, we want to partition by time, in this case with one partition per 
day.   Most of the "get the logs" queries will use a limited time range,
 invoking query pruning and allowing a quick response.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
tricky part is, the DB server does not automatically create and destroy 
partitions.  We need to do that.  It's pretty straightforward with 
stored procedures, though.  Here's the resulting SQL to create the logs 
table:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">DROP TABLE IF EXISTS logs;
CREATE TABLE logs (
    -- foreign key for the board
    board_id integer not null,
    ts timestamp not null,
    -- short string giving the origin of the message (syslog, api, etc.)
    source varchar(32) not null,
    -- the message itself
    message text not null,
    -- indices
    index board_id_idx (board_id),
    index ts_idx (ts)
);

--
-- automated log partition handling
--

DELIMITER $$

-- Procedure to initialize partitioning on the logs table
DROP PROCEDURE IF EXISTS init_log_partitions $$
CREATE PROCEDURE init_log_partitions(days_past INT, days_future INT)
BEGIN
    DECLARE newpart integer;
    SELECT UNIX_TIMESTAMP(NOW()) INTO newpart;
    SELECT newpart - (newpart % 86400) INTO newpart; -- round down to the previous whole day

    -- add partitions, with a single partition for the beginning of the current day, then
    -- let update_log_partitions take it from there
    SET @sql := CONCAT('ALTER TABLE logs PARTITION BY RANGE (UNIX_TIMESTAMP(ts)) ('
                        , 'PARTITION p'
                        , CAST(newpart as char(16))
                        , ' VALUES LESS THAN ('
                        , CAST(newpart as char(16))
                        , '));');
    PREPARE stmt FROM @sql;
    EXECUTE stmt;
    DEALLOCATE PREPARE stmt;

    -- do an initial update to get things synchronized
    call update_log_partitions(days_past, days_future);
END $$

-- Procedure to delete old partitions and create new ones around the current date
DROP PROCEDURE IF EXISTS update_log_partitions $$
CREATE PROCEDURE update_log_partitions(days_past INT, days_future INT)
BEGIN
    DECLARE part integer;
    DECLARE newpart integer;
    DECLARE earliest integer;
    DECLARE latest integer;

    -- add new partitions; keep adding a partition for a new day until we reach latest
    SELECT UNIX_TIMESTAMP(NOW()) + 86400 * (days_future+1) INTO latest;
    createloop: LOOP
        -- Get the newest partition (PARTITION_DESCRIPTION is the number from VALUES LESS THAN)
        -- partitions are named similarly, with a 'p' prefix
        SELECT MAX(PARTITION_DESCRIPTION) INTO part
            FROM INFORMATION_SCHEMA.PARTITIONS
            WHERE TABLE_NAME='logs'
            AND TABLE_SCHEMA='imagingservice';
        IF part &lt; latest THEN -- note part cannot be NULL, as there must be at least one partition
            SELECT part + 86400 INTO newpart;
            SET @sql := CONCAT('ALTER TABLE logs ADD PARTITION ( PARTITION p'
                                , CAST(newpart as char(16))
                                , ' VALUES LESS THAN ('
                                , CAST(newpart as char(16))
                                , '));');
            PREPARE stmt FROM @sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
        ELSE
            LEAVE createloop;
        END IF;
    END LOOP;

    -- now, deal with pruning old partitions; select the minimum partition
    -- and delete it if it's too old
    SELECT UNIX_TIMESTAMP(NOW()) - 86400 * (days_past+1) INTO earliest;
    purgeloop: LOOP
        -- Get the oldest partition
        SELECT MIN(PARTITION_DESCRIPTION) INTO part
            FROM INFORMATION_SCHEMA.PARTITIONS
            WHERE TABLE_NAME='logs'
            AND TABLE_SCHEMA='imagingservice';
        IF part &lt; earliest THEN
            SET @sql := CONCAT('ALTER TABLE logs DROP PARTITION p'
                                , CAST(part as char(16))
                                , ';');
            PREPARE stmt FROM @sql;
            EXECUTE stmt;
            DEALLOCATE PREPARE stmt;
        ELSE
            LEAVE purgeloop;
        END IF;
    END LOOP;
END $$

DELIMITER ;

-- initialize the partitioning
CALL init_log_partitions(14, 1);

-- and then update every day (this can't be set up in init_log_partitions)
DROP EVENT IF EXISTS update_log_partitions;
CREATE EVENT update_log_partitions  ON SCHEDULE EVERY 1 day
DO CALL update_log_partitions(14, 1);
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">A few
 notes here.  First, the table is created without any partitions.  This 
is because I don't know a priori which partitions it should have, and 
it's easier to get code to figure that out than do it myself.  That's 
what the <tt>init<em>log</em>partitions</tt> function does.  The <tt>update<em>log</em>partitions</tt>
 function looks at the current time and makes sure there are enough 
partitions for the future, and drops partitions too far in the past.  
Finally, a MySQL event is set up to update the partitions daily.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">You'll need to enable the event scheduler globally to get this to run:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">set global event_scheduler=on;
</pre></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/77-Google-Dependency...html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Google Dependency..</span></a><div class="lastUpdated">September 16, 2012 10:00 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I have a Google-branded <a href="http://www.google.com/nexus/#/galaxy">Samsung Nexus</a>, runny Jelly Bean.  It's a decent phone, except that its GPS requires a small nuclear reactor to power it.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Today S and I drove back from a weekend trip to New Haven, CT.  Google let us down pretty badly.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">First,
 on the way out, I had used the navigation feature (which requires GPS, 
not just Google Location Service) for most of the day.  I have a power 
adapter in the car, and the phone was plugged in the whole time.  Still,
 after about 6 hours, the phone's battery was at about 10% -- having 
started at a full charge when we left.  I forgot to plug it in where we 
spent the night, so it was dead in the morning.  No problem -- I only 
need to navigate home, so I'll just plug it in!</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">And 
here we reach the first problem.  This phone takes 4-6 minutes to start 
up.  Which means either I key in my destination while already on the 
highway, or sit in the car for 4-6 minutes while my phone starts up.  
Bear in mind that during most of that startup time, it has a blank 
screen with no backlight, and sometimes startup crashes, so it's a bit 
of a psychological game to resist popping out the battery early.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Fine,
 so it starts up, I start the navigation application, and hit "Go Home".
  It plots a route, I take off, get on the highway, and the phone dies. 
 At this point I do the math -- if my phone went from 100% to 10% in 6 
hours while navigating, then it requires the combined power of both the 
battery <em>and</em> the adapter to run the navigation app.  So I 
dutifully hand the phone to S to start back up and hit the "Go Home" 
button again.  I immediately turn off the backlight and hope for the 
best.  The navigation voice tells me to head South for 40 miles, and 
then I hear nothing.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
should have been a red flag, but I was too busy composing this blog 
entry in my head to do a little more arithmetic: Albany is not South of 
New Haven.  A half-hour later, S checked her iPhone and pointed out we 
were heading the wrong direction.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
pulled over and checked my phone.  Surprisingly, it was still on!  
However, it was navigating to Waters View, NY, which is not where we 
live.  We live at  Waters View Circle, Cohoes, NY.  Google knows this.  
It's set in the navigation app.  It turns out that Google takes the 
string you type in for your home address and hits the API equivalent of 
the "I'm feeling lucky" button, and you're off to the races.  Perhaps 
not the races you were looking for.  This is the same fundamental flaw 
as plagues Google Now.  If you're in, say, Springfield, MA, but for 
whatever reason the location-aware "I'm feeling lucky" feels 
Springfield, IL is the more relevant search result, you get Springfield,
 IL's  weather.  And it helpfully just says "Springfield" on the card, 
so you don't know anything's wrong until it claims there's torrential 
rains on a clear day.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">At 
this point we killed my phone and navigated the old-fashioned way - 
getting directions on the iPhone and following the relevant signs.  It 
turns out we had a great drive along the Taconic State Parkway, which is
 a far sight more interesting than I-90, so that was OK.  And we only 
lost an hour of drive-time.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Aside
 from the battery-life issues, which are not surprising from Samsung, 
but are surprising from a phone with "Google" on the back, there's an 
important point here: Google's approach to problems is to throw 
gargantuan amounts of data and CPU at them, and hope the answer's right.
  That's fine for search, but when it comes down to building a reliable 
personal device, people need something a little more deterministic.  
Google is increasingly heading toward personalized computing -- Google 
Glass being the ultimate expression -- and I think the company has a lot
 to learn before any of that will be more than an amusingly daft 
automaton. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/78-Documentation-for-MDTs-CustomSettings.ini.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Documentation for MDT's CustomSettings.ini</span></a><div class="lastUpdated">October 25, 2012 11:59 AM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">If
 you're looking for info on CustomSettings.ini, you're most likely to 
find questions answered with "try this script".  You type it in, and if 
it works, great; if not, keep looking.  It's well-nigh impossible to 
find actual documentation, and the programming-by-INI-sections design is
 not exactly intuitive.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">It 
turns out there's some in the help docs for the MDT, but those are a 
.CHM file and Microsoft apparently doesn't post those online.  </p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">However, some helpful (Russian?) souls have done so.  Behold: <a href="http://systemscenter.ru/mdt2012.en/toolkitreference.htm">Microsoft Deployment Toolkit 2012 Toolkit Reference</a>. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/79-Locking-SSH-keys-on-sleep-on-Linux.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Locking SSH keys on sleep on Linux</span></a><div class="lastUpdated">March 29, 2013 12:42 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I
 got a new laptop, a ThinkPad X1 Carbon, and I'm running Linux on it.  
So you're in for a series of posts describing the complex process I had 
to follow to accomplish simple things.  Spoiler alert: 2013 is not the 
year of Linux on the desktop.  It's not looking good for 2014 either.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I'm 
running Fedora 18.  I tried Ubuntu 12.10, but Unity couldn't hold itself
 together long enough to actually do anything, so I started over with 
Fedora.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">SSH Agent</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Gnome runs a nice keychain app that acts like (but is not) OpenSSH's ssh-agent.  The one obvious place it differs is that <tt>ssh-add -l</tt> will list keys even if they are "locked" (passphrase not supplied).</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">As long as you point the SSH<em>AUTH</em>SOCK variable to the right place, the agent works just fine for unlocking keys - it finds any private/public pairs in <tt>~/.ssh</tt>, and prompts to unlock them once you issue an SSH command that needs a key.  The problem is, it never re-locks the keys.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Locking</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Personally,
 I use SSH constantly while my laptop is awake, so I don't want an 
arbitrary timeout.  Instead, I'm careful to put it to sleep when I'm 
away from the keyboard.  So I want a way to lock the key on sleep.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">It 
turns out that pm-utils will run scripts in /etc/pm/sleep.d on sleep and
 wake.  It runs them as root, unfortunately.  I added the following in <tt>01dustin-ssh-agent.sh</tt>:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">#!/bin/sh

# drop keys from dustin's SSH agent

. "${PM_FUNCTIONS}"

lock()
{
        su - dustin /home/dustin/bin/ssh-lock
}

case "$1" in
        hibernate|suspend) lock ;;
        *) exit $NA ;;
esac
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">and then added the following in <tt>~/bin/ssh-lock</tt>:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">#!/bin/sh

# drop keys from the SSH agent, using the same trick as bin/startscreen to find
# that agent

base="/tmp"
[ -d /run/user ] &amp;&amp; base="/run/user/$(id -u)"
socket_dir="$base/$(uname -n)-$(id -u)"
SSH_AUTH_SOCK=$socket_dir/agent ssh-add -D
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">See <a href="http://code.v.igoro.us/archives/60-SSH-With-Snow-Leopard.html">my post</a>
 on tunneling ssh-agent into a screen session for the reference to 
bin/startscreen.  I'm not sure how best to accomplish this without such a
 trick.  I'll work on that and post again. </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/80-910-Days-at-Mozilla.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">910 Days at Mozilla</span></a><div class="lastUpdated">April 15, 2013 2:26 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">As
 of today, I've been at Mozilla for 910 days.  That's not a magic 
number, but this seemed like a good day to reflect on my time here.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I've had a chance to do a bunch of exciting things here:</p>

<ul xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">
<li>Drink from the Mozilla Firehose
</li><li>Manage build slaves in the release engineering environment
</li><li>Build out a configuration management system with Puppet
</li><li>Design systems to build out new hardware platforms and operating systems
</li><li>Organize a move of systems and servers out of one datacenter and into another.
</li><li>Build a web cluster
</li><li>Build and maintain MySQL database clusters as an apprentice DBA
</li><li>Learn Ruby and hack on Puppet
</li><li>Build a dynamic hardware provisioning system (<a href="https://github.com/mozilla/mozpool">Mozpool</a>)
</li></ul>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">You'll
 never be bored at Mozilla!  There's never a shortage of work to do, 
with new projects coming all the time.  The organization is structured 
so that it's easy to take on tasks that need doing, whether they're 
within your skill base or not.  There's lots of room to learn, and 
everyone's happy to teach.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
work with an incredible group of people.  Just within IT, we have a huge
 range of skills and capabilities for a relatively small team.  People 
who know how to <em>really</em> solve problems, not the half-baked 
temporary solutions that you find elsewhere.  As but one example, the 
datacenter operations team is building out and operating several 
world-class datacenters at the same time, and still managing to turn 
around our remote-hands requests in matters of hours.  Our 
infrastructure team is full of people with deep experience in all 
aspects of system administration who are always willing to help solve a 
tricky problem.  And on my own team, my co-workers all manage to work 
miracles far beyond the resources available.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Before
 Mozilla, I was at Zmanda, working on Amanda -- you know, the 
open-source backup application you remember from your early days?  It's 
still around!  Anyway, I took that job in part because it meant I could 
be paid to work on open-source software.  I took full advantage of that 
opportunity, but the company was fundamentally a company - organized 
around sales, support, and the bottom line.  My open-source concerns 
always played second fiddle, if that.  Mozilla's different: the <a href="http://www.mozilla.org/about/manifesto.en.html">Mozilla Manifesto</a> is <em>what we do</em>,
 and that's understood nowhere better than at the top of the 
organization.  It can be a struggle sometimes, to see how the work I do 
supports the people who support the people who build the products that 
further the mission, but the connection is there and it's important.  
That keeps me going.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Here's to another 1000 successful days at Mozilla! </p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/81-Oops,-I-partitioned-my-drive...html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Oops, I partitioned my drive..</span></a><div class="lastUpdated">May 29, 2013 2:48 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I
 did something colossally stupid yesterday.  I was at the local 
hackerspace, hoping to cut some acrylic, and the wifi wasn't working.  I
 was in a hurry and frustrated, so I pulled out a USB stick and tried to
 erase it.  Suffice to say, the USB stick wasn't at <tt>/dev/sda</tt>.  I
 wiped out the GPT on my laptop.  Its disk is encrypted, so the buffer 
store kept things working for a while, then suddenly I had a blinking 
root prompt and .. nothing.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">After
 the obligatory cold-sweat had passed, I quietly packed up and walked 
out.  Here's the story of how I recovered from this, with the help of 
Jake Watkins (:dividehex). The system didn't have any irrecoverable data
 on it.  All of my work is in version-control, and I'm religious about 
pushing to github.  Even my home directory's dotfiles are on github (in a
 private repo).  But I spent several weeks setting this laptop up (Linux
 on the desktop is only usable from a very long-term perspective!), and 
unfortunately one of the few things that wasn't in version control was 
my notes on how I'd done so.  Rebuilding this from scratch would take a 
few weeks and make a very grumpy Dustin.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">To 
make things interesting, this ThinkPad X1 Carbon has no Ethernet port.  
It's wifi only.  There are dongles available from Lenovo, but I don't 
have one.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Backup</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">OK, so let's stop the bleeding.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
booted from the Fedora Live USB stick I'd used to install the system 
initially.  Once it was up, I schlepped the entire drive over to my 
desktop:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">ssh root@ramanujan dd if=/dev/sda &gt; laptop-disk.img
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">That 
took about 8 hours, but that gave me time to do some other research, 
conduct a Baltic Porter tasting (multitasking!), and sleep.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Find the Data</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">So 
the situation is that I have a partition table with a single 256G FAT32 
partition in it.  Somewhere on the disk, my data is probably still 
intact.  But where?</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Jake suggested looking for the GPT backup table, which is at the end of the disk.  The <tt>gdisk</tt> advanced options allow you to examine this table, but it too was empty.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Jake's other suggestion was to look for the signature of the LUKS crypto container.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">dd if=/dev/sda | od -c | grep 'L   U   K   S'
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
eventually turned up the beginning of the partition, 05364000000 
(decimal 735051776) bytes into the disk.  Dividing that by 512, the size
 of a sector, that's sector 1435648.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">In <tt>gdisk</tt>, I created a partition beginning at that location and running to the end of the disk.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"># cryptsetup luksDump /dev/sda1
LUKS header information for /dev/sda1

Version:        1
Cipher name:    aes
Cipher mode:    xts-plain64
Hash spec:      sha1
Payload offset: 4096
MK bits:        512
MK digest:      e2 f9 fa 7d 44 dc 82 f5 3c 39 1d e2 ac 6e e3 d2 d0 f5 2b 1b 
MK salt:        05 8b a0 ee 7a bf 37 73 7b 15 c1 7a 41 0b 46 19 
                56 68 e1 36 f7 7c b3 d0 74 bf 21 98 a1 e6 75 7b 
MK iterations:  13750
UUID:           4057691b-b580-4d05-afd3-9e2efe8d65d3
...
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">so it looks like I've found the data.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"># cryptsetup luksOpen /dev/sda1 secret
  
# mount /dev/mapper/secret /mnt
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
didn't work.  It's not an ext4 volume - it's an LVM physical volume.  
Udev has already run the pvscan, so I just need to activate the volume 
group:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"># vgscan -a y fedora
# mount /dev/fedora/root /mnt
# mount /dev/fedora/home /mnt/home
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">At 
this point, it's time for another backup.  I used tar to dump the 
contents of both partitions, storing the tarball on my desktop machine. 
 This took about an hour.  Now I feel a lot better -- I have my notes 
from customizing the system, and anything else that's not backed up that
 I might have forgotten.  But I haven't actually lost any data - can I 
recover this completely?</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Rebuild It</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">I 
reboot the Live USB stick, just to reset all of the partition maps, luks
 opens, etc. that I had done.  I realize that /dev/sda1 is probably not 
the right partition number for the full filesystem, so I move that to 
/dev/sda3 (by deleting and re-creating with the same first/last 
sectors).  Another reboot.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">When it starts up again, I fire up the installer and tried to install <em>around</em>
 the existing data.  I figure I can do a minimal installation in some of
 the free space, particularly since Anaconda reassured me that it only 
needed 3.1G.  </p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Long 
story short, this was a lie.  Anaconda is a horrible piece of software, 
with bugs galore.  For example, if you set a partition's size, it will 
randomly make up another size and use that instead.  Ugh.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">It 
turns out, Anaconda needs about 15G to do the install.  So, I need to 
shrink /dev/sda3 by at least that much.  I resize logical volumes all 
the time, but this is the reverse -- I need to shrink a physical volume.
  That turns out to be a bit tricky.  First, after opening the LUKS 
volume, I run <tt>pvresize</tt>:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">pvresize --setphysicalvolumesize 210g /dev/mapper/secret
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
fails, telling me that there are extents beyond the new last extent.  
Subtract a few from that last extent and call that $boundary.  Run <tt>pvdisplay /dev/mapper/secret</tt> to get the total physical extents, and call that $total.  Then, use <tt>pvmove</tt> to shift those around:</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">pvmove --alloc anywhere /dev/mapper/secret:$boundary-$total /dev/mapper/secret:0-$boundary
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">and I re-run the <tt>pvresize</tt> command.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Now, I
 resize the LUKS container that PV is housed in.  This requires a little
 arithmetic.  LVM uses "GiB", which are the normal power-of-two things, 
not the stupid disk-manufacturer power-of-ten things.  So 210g is 
225485783040 bytes, which (divided by 512) is 440401920 sectors.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">cryptsetup resize --size 440401920 /dev/mapper/secret
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">OK, I
 shrank the PV, I shrank the enclosing LUKS container, and now I need to
 shrink the partition.  This means deleting and re-adding the partition 
in gdisk.  The starting sector stays the same, while the last sector is 
calculated as $starting_sector + 440401920 - 1.  The -1 is important 
there - I'm specifying the <i>last</i>sector, not the first sector of 
the next partition.  That'd be a sad way to lose 512 bytes of data when I
 least expect it.  The filesystem type doesn't seem to matter - I used 
the default, but I noticed that Anaconda uses 0700.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Reboot
 and run the install again.  Let Anaconda do its thing, because it's not
 going to listen to me if I try to customize it.  Anaconda happened to 
choose a different VG name (fedora_ramanujan) for the new volume group. 
 If it hadn't, I might have had to rename things.  Reboot, and I have a 
fresh system.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">If I was smart, I would have run 'yum upgrade' now, but I didn't.  More on that in a second.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
idea is that I now have UEFI set up, and all of the proper boot 
partitions, but it's running from the wrong encrypted partition.  
Changing that is as simple as editing /boot/efi/EFI/fedora/grub.cfg, 
replacing the new VG name with the old VG name, and the new LUKS UUID 
with the old LUKS UUID (from 'cryptsetup dumpLuks').  Reboot, enter my 
passphrase, and .. "Welcome to emergency mode!".  A bit of poking around
 shows that all of my partitions are mounted properly, but the journal 
shows failures mounting /boot/efi, because of a missing vfat module.</p>

<h2 xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Kernel Woes</h2>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The kernel and initrd are, of course, on /boot, and are the version installed from the Live USB stick.  The kernel <i>modules</i> are on /, and are the updated versions from several months later.  They don't match up.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">The 
quick fix is to mount the new LUKS container and copy /lib/modules over 
/lib/modules on the old container.  This gets me a copy of all of the 
modules that Anaconda had installed, and lets me boot all the way into a
 working system .. almost.  The wifi isn't working.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">This 
is probably because I'm running an old kernel version with an 
otherwise-updated system.  Upgrading to the latest kernel is the fix.  
That's tricky with no wifi, so I look up the packages on my desktop, 
throw them on a USB stick (being very careful not to re-partition my 
desktop's HDD in the process!), and run</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">yum reinstall /mnt/usb/kernel-*
</pre>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">on the laptop once the USB stick is mounted there.  Reboot, and all is back to normal.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">That was not the most fun I've ever had in 20 hours.  But it was an adventure.</p></div></div><div style="clear: both;"></div><div class="entry"><h3><a href="http://code.v.igoro.us/archives/82-Threading-an-SSH-Agent-Through-Screen.html"><span xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Threading an SSH Agent Through Screen</span></a><div class="lastUpdated">November 6, 2013 12:13 PM</div></h3><div xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1" class="feedEntryContent"><p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1"><i>I
 posted this three years ago, buried in an unrelated post, but several 
people have asked me about it lately, so here it is in a dedicated post.</i></p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">You 
should only have your SSH private key on hosts that are physically in 
your posession - laptop, desktop, etc.  But you usually want to put 
those hosts to sleep or move them around, which means they can't keep 
live SSH connections going in a screen session.  So you probably run 
screen on a server somewhere - a VPS, an admin host at work, or if 
you're like me, a server in your basement.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Now 
you have a new problem: when you first start the screen session, your 
SSH agent works fine in screen windows.  But when you disconnect and 
reconnect, all of those screen windows are still looking for the old SSH
 agent, which no longer exists.  So SSH connections in a reconnected 
screen session fail.</p>

<p xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">Well,
 there's a fix!  The idea is to mirror the auth socket to a well-known 
name that is stable from one SSH connection to the next.</p>

<pre xml:base="http://code.v.igoro.us/rss.php?version=2.0&amp;all=1">#! /bin/bash
# hard-link the SSH socket to one with a fixed name on the local
# machine, and set SSH_AUTH_SOCK to point to that fixed name.  Later
# invocations of this script will change the link, but the name will
# remain valid, allowing existing shells to continue to function.
setup_fixed_socket() {
  local old_socket="$SSH_AUTH_SOCK"
  local socket_dir="/tmp/$(uname -n)-$(id -u)"
  local socket_file=$socket_dir/agent

  # set up the directory and permissions
  [ -e $socket_dir ] || mkdir -p $socket_dir
  chmod 700 $socket_dir

  # remove an existing link
  [ -e $socket_file ] &amp;&amp; rm $socket_file

  # hard-link in the new one
  ln $old_socket $socket_file

  # return the new socket
  echo $socket_file
}

# this variable will be exported to every shell opened by this
# invocation of screen -- even subsequent connections to it.  This
# variable may live for days or weeks.
export SSH_AUTH_SOCK=$(setup_fixed_socket)

# finally, fire up screen.  Try reattaching to a running
# session; otherwise start up a new one
screen -R -DD ${@} || screen
</pre></div></div><div style="clear: both;"></div></div>
    </div>
  </body>
</html>